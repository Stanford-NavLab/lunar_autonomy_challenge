{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from lightglue import LightGlue, SuperPoint, viz2d, match_pair\n",
    "from lightglue.utils import rbd\n",
    "\n",
    "from lac.slam.feature_tracker import FeatureTracker\n",
    "from lac.perception.depth import project_pixel_to_rover\n",
    "from lac.utils.frames import apply_transform\n",
    "from lac.utils.plotting import plot_3d_points, plot_surface, plot_poses, plot_path_3d\n",
    "from lac.util import load_data, grayscale_to_3ch_tensor\n",
    "from lac.params import LAC_BASE_PATH, DT\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/home/shared/data_raw/LAC/segmentation/slam_map1_preset1_teleop\")\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)\n",
    "print(f\"Num poses: {len(poses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_imgs = {}\n",
    "right_imgs = {}\n",
    "side_left_imgs = {}\n",
    "side_right_imgs = {}\n",
    "\n",
    "for img_name in tqdm(os.listdir(data_path / \"FrontLeft\")):\n",
    "    left_imgs[int(img_name.split(\".\")[0])] = cv2.imread(str(data_path / \"FrontLeft\" / img_name), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "for img_name in tqdm(os.listdir(data_path / \"FrontRight\")):\n",
    "    right_imgs[int(img_name.split(\".\")[0])] = cv2.imread(str(data_path / \"FrontRight\" / img_name), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "for img_name in tqdm(os.listdir(data_path / \"Left\")):\n",
    "    side_left_imgs[int(img_name.split(\".\")[0])] = cv2.imread(str(data_path / \"Left\" / img_name), cv2.IMREAD_GRAYSCALE)\n",
    "for img_name in tqdm(os.listdir(data_path / \"Right\")):\n",
    "    side_right_imgs[int(img_name.split(\".\")[0])] = cv2.imread(str(data_path / \"Right\" / img_name), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "assert len(left_imgs.keys()) == len(right_imgs.keys())\n",
    "img_idxs = sorted(left_imgs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = FeatureTracker(cam_config)\n",
    "\n",
    "image = side_left_imgs[1500]\n",
    "\n",
    "feats = tracker.extract_feats(image)\n",
    "feats = rbd(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps = feats[\"keypoints\"]\n",
    "good_kps = kps[feats[\"keypoint_scores\"] > 0.05]\n",
    "print(f\"Num keypoints: {len(kps)}, {len(good_kps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz2d.plot_images([image])\n",
    "viz2d.plot_keypoints([kps], ps=10)\n",
    "viz2d.plot_keypoints([good_kps], colors=[\"red\"], ps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGlue Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame indices\n",
    "idx0 = 1500\n",
    "idx1 = idx0 + 6\n",
    "\n",
    "prev_img = side_right_imgs[idx0]\n",
    "next_img = side_right_imgs[idx1]\n",
    "\n",
    "prev_feats = tracker.extract_feats(prev_img)\n",
    "next_feats = tracker.extract_feats(next_img)\n",
    "\n",
    "matches = tracker.match_feats(prev_feats, next_feats)\n",
    "points_prev = prev_feats[\"keypoints\"][0][matches[:, 0]]\n",
    "points_next = next_feats[\"keypoints\"][0][matches[:, 1]]\n",
    "\n",
    "print(len(matches))\n",
    "\n",
    "matches = tracker.match_feats(prev_feats, next_feats, min_score=0.9)\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points0 = points_prev.cpu().numpy()\n",
    "points1 = points_next.cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(next_img, cmap=\"gray\")\n",
    "for i in range(len(matches)):\n",
    "    plt.plot([points0[i, 0], points1[i, 0]], [points0[i, 1], points1[i, 1]], color=\"lime\")\n",
    "    plt.scatter(points1[i, 0], points1[i, 1], color=\"lime\", s=5)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(prev_img, cmap=\"gray\")\n",
    "for i in range(len(matches)):\n",
    "    plt.plot([points0[i, 0], points1[i, 0]], [points0[i, 1], points1[i, 1]], color=\"lime\")\n",
    "    plt.scatter(points0[i, 0], points0[i, 1], color=\"lime\", s=5)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import inv\n",
    "\n",
    "from lac.utils.frames import get_cam_pose_rover, CAMERA_TO_OPENCV_PASSIVE\n",
    "from lac.perception.vision import get_camera_intrinsics\n",
    "\n",
    "# Camera intrinsics and extrinsics\n",
    "K = get_camera_intrinsics(\"Right\", cam_config)\n",
    "rover_T_cam = get_cam_pose_rover(\"Right\")\n",
    "rover_T_cam_ocv = rover_T_cam.copy()\n",
    "rover_T_cam_ocv[:3, :3] = rover_T_cam_ocv[:3, :3] @ CAMERA_TO_OPENCV_PASSIVE\n",
    "\n",
    "# Projection matrices\n",
    "cam_T_world_0 = inv(poses[idx0] @ rover_T_cam_ocv)\n",
    "cam_T_world_1 = inv(poses[idx1] @ rover_T_cam_ocv)\n",
    "\n",
    "P0 = K @ cam_T_world_0[:3]\n",
    "P1 = K @ cam_T_world_1[:3]\n",
    "\n",
    "# Triangulate\n",
    "points_4d_h = cv2.triangulatePoints(P0, P1, points0.T, points1.T)\n",
    "points_3d_est = (points_4d_h[:3] / points_4d_h[3]).T\n",
    "\n",
    "# Estimated depths\n",
    "depths_est = (cam_T_world_0[:3, :3] @ points_3d_est.T + cam_T_world_0[:3, 3:4]).T[:, 2]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(next_img, cmap=\"gray\")\n",
    "for i in range(len(points1)):\n",
    "    plt.plot([points0[i, 0], points1[i, 0]], [points0[i, 1], points1[i, 1]], color=\"lime\")\n",
    "    x, y = points1[i]\n",
    "    plt.scatter(x, y, color=\"lime\", s=5)\n",
    "    plt.text(x + 2, y, f\"{depths_est[i]:.2f}\", color=\"red\", fontsize=8)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_2d_0, points_2d_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import graph_objects as go\n",
    "from lac.utils.plotting import plot_poses\n",
    "\n",
    "idx0 = 1500\n",
    "idx1 = idx0 + 10\n",
    "\n",
    "# Synthetic 3D points in camera frame 0\n",
    "points_cam = np.array(\n",
    "    [\n",
    "        [0.0, 0.0, 2.0],\n",
    "        [-1.0, 0.0, 3.0],\n",
    "        [0.0, -1.5, 4.0],\n",
    "    ]\n",
    ")\n",
    "points_cam_h = np.hstack((points_cam, np.ones((points_cam.shape[0], 1))))\n",
    "points_world = (poses[idx0] @ rover_T_cam_ocv @ points_cam_h.T).T\n",
    "\n",
    "# World to camera transforms\n",
    "cam_T_world_0 = np.linalg.inv(poses[idx0] @ rover_T_cam_ocv)\n",
    "cam_T_world_1 = np.linalg.inv(poses[idx1] @ rover_T_cam_ocv)\n",
    "\n",
    "points_world_h = np.hstack((points_world[:, :3], np.ones((points_world.shape[0], 1))))\n",
    "points_cam_0 = (cam_T_world_0 @ points_world_h.T).T[:, :3]\n",
    "points_cam_1 = (cam_T_world_1 @ points_world_h.T).T[:, :3]\n",
    "\n",
    "# Project to 2D image points\n",
    "points_2d_0 = (K @ points_cam_0.T).T\n",
    "points_2d_0 = (points_2d_0[:, :2].T / points_2d_0[:, 2]).T\n",
    "\n",
    "points_2d_1 = (K @ points_cam_1.T).T\n",
    "points_2d_1 = (points_2d_1[:, :2].T / points_2d_1[:, 2]).T\n",
    "\n",
    "# Projection matrices\n",
    "P0 = K @ cam_T_world_0[:3]\n",
    "P1 = K @ cam_T_world_1[:3]\n",
    "\n",
    "# Triangulate\n",
    "points_4d_h = cv2.triangulatePoints(P0, P1, points_2d_0.T, points_2d_1.T)\n",
    "points_3d_est = (points_4d_h[:3] / points_4d_h[3]).T\n",
    "\n",
    "# Estimated depths\n",
    "depths_est = (cam_T_world_0[:3, :3] @ points_3d_est.T + cam_T_world_0[:3, 3:4]).T[:, 2]\n",
    "\n",
    "# Ground truth depths\n",
    "gt_depths = points_cam_0[:, 2]\n",
    "\n",
    "print(f\"GT depths: {gt_depths}\")\n",
    "print(f\"Estimated depths: {depths_est}\")\n",
    "\n",
    "# Optional: visualize\n",
    "fig = go.Figure()\n",
    "plot_poses([poses[idx0], poses[idx1]], fig)\n",
    "plot_poses([poses[idx0] @ rover_T_cam_ocv], fig)\n",
    "plot_poses([poses[idx1] @ rover_T_cam_ocv], fig)\n",
    "fig.add_scatter3d(\n",
    "    x=points_world[:, 0],\n",
    "    y=points_world[:, 1],\n",
    "    z=points_world[:, 2],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=5, color=\"red\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(next_img, cmap=\"gray\")\n",
    "for i in range(len(points_2d_1)):\n",
    "    plt.plot([points_2d_0[i, 0], points_2d_1[i, 0]], [points_2d_0[i, 1], points_2d_1[i, 1]])\n",
    "    plt.scatter(points_2d_0[i, 0], points_2d_0[i, 1], s=5, color=f\"C{i}\")\n",
    "    plt.scatter(points_2d_1[i, 0], points_2d_1[i, 1], s=20, color=f\"C{i}\")\n",
    "    plt.text(points_2d_1[i, 0] + 2, points_2d_1[i, 1], f\"{depths_est[i]:.2f}\", color=\"red\", fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
