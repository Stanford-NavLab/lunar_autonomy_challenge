{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from gtsam.symbol_shorthand import X\n",
    "import matplotlib.pyplot as plt\n",
    "from lac.perception.depth import (\n",
    "    stereo_depth_from_segmentation,\n",
    "    project_pixel_to_world,\n",
    "    project_pixels_to_world,\n",
    ")\n",
    "\n",
    "from lac.slam.feature_tracker import FeatureTracker, prune_features\n",
    "from lac.perception.segmentation import UnetSegmentation\n",
    "from lac.utils.plotting import plot_poses, plot_surface, plot_3d_points\n",
    "from lac.util import load_data, load_stereo_images, load_side_images\n",
    "from lac.utils.visualization import overlay_mask\n",
    "from lac.params import LAC_BASE_PATH\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data logs\n",
    "# data_path = Path(\"/home/shared/data_raw/LAC/segmentation/slam_map1_preset1_teleop\")\n",
    "data_path = Path(\"/home/shared/data_raw/LAC/runs/full_spiral_map1_preset1_recovery_agent\")\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)\n",
    "print(f\"Loaded {len(poses)} poses\")\n",
    "\n",
    "# Load the images\n",
    "df = 8\n",
    "left_imgs, right_imgs = load_stereo_images(data_path, step=df)\n",
    "side_left_imgs, side_right_imgs = load_side_images(data_path, step=df)\n",
    "\n",
    "# Load the ground truth map\n",
    "map = np.load(\n",
    "    \"/home/shared/data_raw/LAC/heightmaps/competition/Moon_Map_01_preset_1.dat\",\n",
    "    allow_pickle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = UnetSegmentation()\n",
    "feature_tracker = FeatureTracker(cam_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frontend:\n",
    "\n",
    "- Run both segmentation and feature extraction on left and right images\n",
    "- Triangulate feature matches. For keypoints labeled as rock, group them together\n",
    "\n",
    "Rock map:\n",
    "\n",
    "- Each rock has a set of world points with associated descriptors (these descriptors should probably also be associated with a viewing direction since the apperance of a rock can change with viewing direction)\n",
    "-\n",
    "\n",
    "Graph SLAM:\n",
    "\n",
    "- In the graph, we have a landmark for each rock corresponding to its centroid point\n",
    "- For each keyframe, we determine the observed pixel centroid of the rock based on segementation outputs, and use that to add reprojection factors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from lac.perception.depth import stereo_depth_from_segmentation, project_pixel_to_world\n",
    "from lac.utils.plotting import plot_rock_map\n",
    "from lac.utils.visualization import int_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = UnetSegmentation()\n",
    "feature_tracker = FeatureTracker(cam_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.perception.vision import get_camera_intrinsics\n",
    "from lac.utils.frames import get_cam_pose_rover, CAMERA_TO_OPENCV_PASSIVE\n",
    "from scipy.linalg import inv\n",
    "\n",
    "# def get_depths_mono(cam_name, points0, points1, prev_pose, curr_pose):\n",
    "\n",
    "frame = 200\n",
    "cam_name = \"Right\"\n",
    "img0 = side_left_imgs[frame - df]\n",
    "img1 = side_left_imgs[frame]\n",
    "prev_pose = poses[frame - df]\n",
    "curr_pose = poses[frame]\n",
    "\n",
    "# Camera intrinsics and extrinsics\n",
    "K = get_camera_intrinsics(cam_name, cam_config)\n",
    "rover_T_cam = get_cam_pose_rover(cam_name)\n",
    "rover_T_cam_ocv = rover_T_cam.copy()\n",
    "rover_T_cam_ocv[:3, :3] = rover_T_cam_ocv[:3, :3] @ CAMERA_TO_OPENCV_PASSIVE\n",
    "\n",
    "# Projection matrices\n",
    "cam_T_world_0 = inv(prev_pose @ rover_T_cam_ocv)\n",
    "cam_T_world_1 = inv(curr_pose @ rover_T_cam_ocv)\n",
    "\n",
    "P0 = K @ cam_T_world_0[:3]\n",
    "P1 = K @ cam_T_world_1[:3]\n",
    "\n",
    "points_cam = np.array(\n",
    "    [\n",
    "        [0.0, 0.0, 2.0],\n",
    "        [-1.0, 0.0, 3.0],\n",
    "        [0.0, -1.5, 4.0],\n",
    "    ]\n",
    ")\n",
    "points_cam_h = np.hstack((points_cam, np.ones((points_cam.shape[0], 1))))\n",
    "points_world = (prev_pose @ rover_T_cam_ocv @ points_cam_h.T).T\n",
    "points_world_h = np.hstack((points_world[:, :3], np.ones((points_world.shape[0], 1))))\n",
    "points_cam_0 = (cam_T_world_0 @ points_world_h.T).T[:, :3]\n",
    "points_cam_1 = (cam_T_world_1 @ points_world_h.T).T[:, :3]\n",
    "\n",
    "points0 = (K @ points_cam_0.T).T\n",
    "points0 = (points0[:, :2].T / points0[:, 2]).T\n",
    "points1 = (K @ points_cam_1.T).T\n",
    "points1 = (points1[:, :2].T / points1[:, 2]).T\n",
    "\n",
    "# Triangulate\n",
    "points_4d_h = cv2.triangulatePoints(P0, P1, points0.T, points1.T)\n",
    "points_3d_est = (points_4d_h[:3] / points_4d_h[3]).T\n",
    "depths_est = (cam_T_world_1[:3, :3] @ points_3d_est.T + cam_T_world_1[:3, 3:4]).T[:, 2]\n",
    "\n",
    "print(depths_est)\n",
    "\n",
    "# return points_3d_next, depths_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.perception.matching import get_depths_mono, get_submask, insert_submask\n",
    "\n",
    "frame = 200\n",
    "cam_name = \"Right\"\n",
    "img0 = side_left_imgs[frame - df]\n",
    "img1 = side_left_imgs[frame]\n",
    "prev_pose = poses[frame - df]\n",
    "curr_pose = poses[frame]\n",
    "\n",
    "get_depths_mono(\n",
    "    cam_name,\n",
    "    cam_config,\n",
    "    np.array([640, 360]),\n",
    "    np.array([704.33040004, 377.72892952]),\n",
    "    prev_pose,\n",
    "    curr_pose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.perception.segmentation_util import get_mask_centroids, centroid_matching\n",
    "from lac.params import FL_X, STEREO_BASELINE\n",
    "\n",
    "frame = 200\n",
    "cam_name = \"Right\"\n",
    "img0 = side_left_imgs[frame - df]\n",
    "img1 = side_left_imgs[frame]\n",
    "prev_pose = poses[frame - df]\n",
    "curr_pose = poses[frame]\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def process_match(args):\n",
    "    centroid0, centroid1, mask0, mask1, cam_name, cam_config, curr_pose, prev_pose = args\n",
    "\n",
    "    if mask0.sum() < 100 or mask1.sum() < 100:\n",
    "        return None\n",
    "\n",
    "    height = np.max(np.where(mask0)[1]) - np.min(np.where(mask0)[1]) + 1\n",
    "    width = np.max(np.where(mask0)[0]) - np.min(np.where(mask0)[0]) + 1\n",
    "    size = (width, height)\n",
    "\n",
    "    best_submask, best_score = None, 0\n",
    "    for dx in range(-2, 2):\n",
    "        for dy in range(-2, 2):\n",
    "            center0 = (centroid0[0], centroid0[1])\n",
    "            center1 = (centroid1[0] + dx, centroid1[1] + dy)\n",
    "            mask0_new = np.logical_and(\n",
    "                mask0, insert_submask(np.zeros_like(mask0), np.ones(size, np.uint8), center0)\n",
    "            )\n",
    "            mask1_new = np.logical_and(\n",
    "                mask1, insert_submask(np.zeros_like(mask1), np.ones(size, np.uint8), center1)\n",
    "            )\n",
    "            submask0 = get_submask(mask0_new, size, centroid0)\n",
    "            submask1 = get_submask(mask1_new, size, centroid1)\n",
    "            submask = np.logical_and(submask0, submask1)\n",
    "            score = np.sum(submask)\n",
    "            if score > best_score:\n",
    "                best_score, best_submask = score, submask\n",
    "\n",
    "    if best_submask is not None:\n",
    "        mask0_common = insert_submask(np.zeros_like(mask0), best_submask, centroid0)\n",
    "        mask1_common = insert_submask(np.zeros_like(mask1), best_submask, centroid1)\n",
    "        centroid0_new = np.mean(np.array(np.argwhere(mask0_common)).T, axis=1)[::-1]\n",
    "        centroid1_new = np.mean(np.array(np.argwhere(mask1_common)).T, axis=1)[::-1]\n",
    "    else:\n",
    "        centroid0_new, centroid1_new = centroid0, centroid1\n",
    "\n",
    "    if \"Front\" in cam_name:\n",
    "        disparity = centroid0_new[0] - centroid1_new[0] + 1e-8\n",
    "        depth = (FL_X * STEREO_BASELINE) / disparity\n",
    "        centroid = project_pixel_to_world(curr_pose, centroid0_new, depth, \"FrontLeft\", cam_config)\n",
    "    else:\n",
    "        _, depth = get_depths_mono(cam_name, centroid0_new, centroid1_new, prev_pose, curr_pose)\n",
    "        depth = depth[0]\n",
    "        centroid = project_pixel_to_world(curr_pose, centroid0_new, depth, cam_name, cam_config)\n",
    "\n",
    "    if 0 < depth < 5:\n",
    "        return centroid\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_rock_centroids(cam_name, img0, img1, curr_pose, prev_pose=None, refine_centroids=True):\n",
    "    seg_masks0, labels0 = segmentation.segment_rocks(img0)\n",
    "    seg_masks1, labels1 = segmentation.segment_rocks(img1)\n",
    "    if len(seg_masks0) == 0 or len(seg_masks1) == 0:\n",
    "        return []\n",
    "    centroids0, centroids1 = get_mask_centroids(seg_masks0), get_mask_centroids(seg_masks1)\n",
    "    matches = centroid_matching(centroids0, centroids1, max_y_diff=100, max_x_diff=100)\n",
    "\n",
    "    all_centroids = []\n",
    "    if not refine_centroids:\n",
    "        for match in matches:\n",
    "            centroid0, centroid1 = centroids0[match[0]], centroids1[match[1]]\n",
    "            if \"Front\" in cam_name:\n",
    "                disparity = centroid0[0] - centroid1[0] + 1e-8\n",
    "                depth = (FL_X * STEREO_BASELINE) / disparity\n",
    "                centroid = project_pixel_to_world(\n",
    "                    curr_pose, centroid0, depth, \"FrontLeft\", cam_config\n",
    "                )\n",
    "            else:\n",
    "                _, depth = get_depths_mono(cam_name, centroid0, centroid1, prev_pose, curr_pose)\n",
    "                depth = depth[0]\n",
    "                centroid = project_pixel_to_world(curr_pose, centroid0, depth, cam_name, cam_config)\n",
    "            all_centroids.append(centroid)\n",
    "        return all_centroids\n",
    "\n",
    "    # Refine\n",
    "    for match in matches:\n",
    "        c = process_match(\n",
    "            (\n",
    "                centroids0[match[0]],\n",
    "                centroids1[match[1]],\n",
    "                seg_masks0[match[0]],\n",
    "                seg_masks1[match[1]],\n",
    "                cam_name,\n",
    "                cam_config,\n",
    "                curr_pose,\n",
    "                prev_pose,\n",
    "            )\n",
    "        )\n",
    "        if c is not None:\n",
    "            all_centroids.append(c)\n",
    "\n",
    "    return all_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_FRAME = 80\n",
    "END_FRAME = START_FRAME + 100\n",
    "END_FRAME = max(left_imgs.keys())\n",
    "\n",
    "centroids_no_refine = []\n",
    "for frame in tqdm(range(START_FRAME, END_FRAME, 4 * df)):\n",
    "    centroids_no_refine.extend(\n",
    "        get_rock_centroids(\n",
    "            \"FrontLeft\", left_imgs[frame], right_imgs[frame], poses[frame], refine_centroids=False\n",
    "        )\n",
    "    )\n",
    "    # for df in range(10, 14, 2):\n",
    "    #     centroids.extend(get_rock_centroids(\"Left\", side_left_imgs[frame-df], side_left_imgs[frame], poses[frame], poses[frame - df]))\n",
    "    #     centroids.extend(get_rock_centroids(\"Right\", side_right_imgs[frame-df], side_right_imgs[frame], poses[frame], poses[frame - df]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_FRAME = 80\n",
    "END_FRAME = START_FRAME + 100\n",
    "END_FRAME = max(left_imgs.keys())\n",
    "\n",
    "centroids = []\n",
    "for frame in tqdm(range(START_FRAME, END_FRAME, 4 * df)):\n",
    "    centroids.extend(\n",
    "        get_rock_centroids(\"FrontLeft\", left_imgs[frame], right_imgs[frame], poses[frame])\n",
    "    )\n",
    "    # for df in range(10, 14, 2):\n",
    "    #     centroids.extend(get_rock_centroids(\"Left\", side_left_imgs[frame-df], side_left_imgs[frame], poses[frame], poses[frame - df]))\n",
    "    #     centroids.extend(get_rock_centroids(\"Right\", side_right_imgs[frame-df], side_right_imgs[frame], poses[frame], poses[frame - df]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_FRAME = 80\n",
    "END_FRAME = max(left_imgs.keys())\n",
    "END_FRAME = START_FRAME + 5000\n",
    "\n",
    "centroids_1st = []\n",
    "for frame in tqdm(range(START_FRAME, END_FRAME, 4 * df)):\n",
    "    centroids_1st.extend(\n",
    "        get_rock_centroids(\n",
    "            \"FrontLeft\", left_imgs[frame], right_imgs[frame], poses[frame], refine_centroids=False\n",
    "        )\n",
    "    )\n",
    "    # for df in range(10, 14, 2):\n",
    "    #     centroids.extend(get_rock_centroids(\"Left\", side_left_imgs[frame-df], side_left_imgs[frame], poses[frame], poses[frame - df]))\n",
    "    #     centroids.extend(get_rock_centroids(\"Right\", side_right_imgs[frame-df], side_right_imgs[frame], poses[frame], poses[frame - df]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = np.min(map[:, :, 0]), np.max(map[:, :, 0])\n",
    "ymin, ymax = np.min(map[:, :, 1]), np.max(map[:, :, 1])\n",
    "nx, ny = map.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.perception.matching import get_rocks_score\n",
    "\n",
    "centroids_1st = np.array(centroids_1st)\n",
    "agent_map = np.zeros_like(map)\n",
    "for c in centroids_1st:\n",
    "    i = int((c[0] - xmin) / (xmax - xmin) * nx)\n",
    "    j = int((c[1] - ymin) / (ymax - ymin) * ny)\n",
    "    if 0 <= i < nx and 0 <= j < ny:\n",
    "        agent_map[i, j, 3] = 1.0\n",
    "\n",
    "print(get_rocks_score(map, agent_map))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(map[:, :, 3], cmap=\"gray\")\n",
    "ax[1].imshow(agent_map[:, :, 3], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.perception.matching import get_rocks_score\n",
    "\n",
    "centroids_no_refine = np.array(centroids_no_refine)\n",
    "agent_map = np.zeros_like(map)\n",
    "for c in centroids_no_refine:\n",
    "    i = int((c[0] - xmin) / (xmax - xmin) * nx)\n",
    "    j = int((c[1] - ymin) / (ymax - ymin) * ny)\n",
    "    if 0 <= i < nx and 0 <= j < ny:\n",
    "        agent_map[i, j, 3] = 1.0\n",
    "\n",
    "print(get_rocks_score(map, agent_map))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(map[:, :, 3], cmap=\"gray\")\n",
    "ax[1].imshow(agent_map[:, :, 3], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.perception.matching import get_rocks_score\n",
    "\n",
    "agent_map = np.zeros_like(map)\n",
    "for c in centroids:\n",
    "    i = int((c[0] - xmin) / (xmax - xmin) * nx)\n",
    "    j = int((c[1] - ymin) / (ymax - ymin) * ny)\n",
    "    if 0 <= i < nx and 0 <= j < ny:\n",
    "        agent_map[i, j, 3] = 1.0\n",
    "\n",
    "print(get_rocks_score(map, agent_map))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(map[:, :, 3], cmap=\"gray\")\n",
    "ax[1].imshow(agent_map[:, :, 3], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig = plot_rock_map(map, fig=fig)\n",
    "fig = plot_poses(poses, fig=fig, no_axes=True, color=\"black\")\n",
    "fig = plot_poses([poses[END_FRAME]], fig=fig, no_axes=False, color=\"black\")\n",
    "fig.add_scatter3d(\n",
    "    x=centroids[:, 0],\n",
    "    y=centroids[:, 1],\n",
    "    z=centroids[:, 2],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=3, color=\"green\"),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END_FRAME = img_idxs[-1]\n",
    "END_FRAME = 2000\n",
    "for frame in tqdm(range(2, END_FRAME, 2)):\n",
    "    left_seg_masks, left_seg_labels = segmentation.segment_rocks(left_imgs[frame])\n",
    "    right_seg_masks, right_seg_labels = segmentation.segment_rocks(right_imgs[frame])\n",
    "    left_seg_full_mask = np.clip(left_seg_labels, 0, 1)\n",
    "\n",
    "    stereo_depth_results = stereo_depth_from_segmentation(\n",
    "        left_seg_masks, right_seg_masks, STEREO_BASELINE, FL_X\n",
    "    )\n",
    "\n",
    "    detections = []\n",
    "    centroids = []\n",
    "    for result in stereo_depth_results:\n",
    "        centroid = result[\"left_centroid\"]\n",
    "        depth = result[\"depth\"]\n",
    "        if depth < 5.0:\n",
    "            rock_point_world_frame = project_pixel_to_world(\n",
    "                poses[frame], centroid, result[\"depth\"], \"FrontLeft\", cam_config\n",
    "            )\n",
    "            centroids.append(centroid)\n",
    "            detections.append(Detection(points=centroid, data=rock_point_world_frame))\n",
    "    tracked_objects = tracker.update(detections)\n",
    "\n",
    "    for rock in tracked_objects:\n",
    "        centroid_pixel = rock.last_detection.points[0]\n",
    "        if rock.id not in rock_detections:\n",
    "            rock_detections[rock.id] = {\"frame\": [], \"points\": [], \"pixels\": []}\n",
    "        rock_detections[rock.id][\"frame\"].append(frame)\n",
    "        rock_detections[rock.id][\"points\"].append(rock.last_detection.data)\n",
    "        rock_detections[rock.id][\"pixels\"].append(centroid_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig = plot_rock_map(map, fig=fig)\n",
    "fig = plot_poses(poses, fig=fig, no_axes=True, color=\"black\")\n",
    "for id, detections in rock_detections.items():\n",
    "    points = np.array(detections[\"points\"])\n",
    "    fig = plot_3d_points(\n",
    "        points, fig=fig, color=int_to_color(id, hex=True), markersize=2, name=f\"rock_{id}\"\n",
    "    )\n",
    "    avg_point = np.mean(points, axis=0)\n",
    "    fig = plot_3d_points(\n",
    "        avg_point[None, :],\n",
    "        fig=fig,\n",
    "        color=int_to_color(id, hex=True),\n",
    "        markersize=5,\n",
    "        name=f\"rock_{id}_avg\",\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtsam\n",
    "from gtsam.symbol_shorthand import X, L\n",
    "\n",
    "from lac.slam.visual_odometry import StereoVisualOdometry\n",
    "from lac.slam.slam import ROVER_T_CAM\n",
    "from lac.params import FL_X, FL_Y, IMG_HEIGHT, IMG_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo = StereoVisualOdometry(cam_config)\n",
    "START_FRAME = 80\n",
    "svo.initialize(initial_pose, left_imgs[START_FRAME], right_imgs[START_FRAME])\n",
    "\n",
    "# Pre-process the VO\n",
    "svo_poses = [initial_pose]\n",
    "pose_deltas = []\n",
    "\n",
    "END_FRAME = 4500\n",
    "\n",
    "for idx in tqdm(np.arange(START_FRAME + 2, END_FRAME, 2)):\n",
    "    svo.track(left_imgs[idx], right_imgs[idx])\n",
    "    svo_poses.append(svo.rover_pose)\n",
    "    pose_deltas.append(svo.pose_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXEL_NOISE = gtsam.noiseModel.Isotropic.Sigma(2, 5.0)\n",
    "K = gtsam.Cal3_S2(FL_X, FL_Y, 0.0, IMG_WIDTH / 2, IMG_HEIGHT / 2)\n",
    "\n",
    "svo_pose_sigma = 1e-2 * np.ones(6)\n",
    "svo_pose_noise = gtsam.noiseModel.Diagonal.Sigmas(svo_pose_sigma)\n",
    "\n",
    "graph = gtsam.NonlinearFactorGraph()\n",
    "values = gtsam.Values()\n",
    "\n",
    "values.insert(X(0), gtsam.Pose3(initial_pose))\n",
    "graph.add(gtsam.NonlinearEqualityPose3(X(0), gtsam.Pose3(initial_pose)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_to_i = {0: 0}\n",
    "\n",
    "# Add poses and VO odometry\n",
    "i = 1\n",
    "for frame in range(START_FRAME, END_FRAME - 2, 2):\n",
    "    frame_to_i[frame] = i\n",
    "    # values.insert(X(i), gtsam.Pose3(poses[frame]))\n",
    "    values.insert(X(i), gtsam.Pose3(svo_poses[i]))\n",
    "    graph.push_back(\n",
    "        gtsam.BetweenFactorPose3(X(i - 1), X(i), gtsam.Pose3(pose_deltas[i - 1]), svo_pose_noise)\n",
    "    )\n",
    "    i += 1\n",
    "\n",
    "active_rock_ids = {}\n",
    "rock_id_count = 0\n",
    "\n",
    "# Add rock landmarks and observations\n",
    "for id, detections in rock_detections.items():\n",
    "    points = np.array(detections[\"points\"])\n",
    "    pixels = np.array(detections[\"pixels\"])\n",
    "    frames = np.array(detections[\"frame\"])\n",
    "    avg_point = np.median(points, axis=0)\n",
    "\n",
    "    for j in range(len(frames)):\n",
    "        if frames[j] not in frame_to_i:\n",
    "            continue\n",
    "\n",
    "        if id not in active_rock_ids:\n",
    "            active_rock_ids[id] = rock_id_count\n",
    "            rock_id_count += 1\n",
    "            values.insert(L(active_rock_ids[id]), avg_point)\n",
    "\n",
    "        i = frame_to_i[frames[j]]\n",
    "        graph.add(\n",
    "            gtsam.GenericProjectionFactorCal3_S2(\n",
    "                pixels[j], PIXEL_NOISE, X(i), L(active_rock_ids[id]), K, ROVER_T_CAM\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = gtsam.LevenbergMarquardtParams()\n",
    "params.setVerbosity(\"TERMINATION\")\n",
    "optimizer = gtsam.LevenbergMarquardtOptimizer(graph, values, params)\n",
    "result = optimizer.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_poses = [result.atPose3(X(k)).matrix() for k in range(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(poses[80:END_FRAME], no_axes=True, color=\"black\", name=\"Ground Truth\")\n",
    "fig = plot_poses(opt_poses, no_axes=True, fig=fig, color=\"green\", name=\"Opt\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
