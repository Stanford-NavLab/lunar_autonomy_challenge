{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from lightglue import LightGlue, SuperPoint, viz2d, match_pair\n",
    "from lightglue.utils import rbd\n",
    "\n",
    "from lac.slam.feature_tracker import FeatureTracker\n",
    "from lac.perception.depth import project_pixel_to_rover\n",
    "from lac.utils.frames import apply_transform\n",
    "from lac.utils.plotting import plot_3d_points, plot_surface, plot_poses, plot_path_3d\n",
    "from lac.util import load_data, load_stereo_images, load_images\n",
    "from lac.params import LAC_BASE_PATH, DT\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load some data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = Path(LAC_BASE_PATH) / \"output/DataCollectionAgent/stereo_lights1.0_map1_preset0\"\n",
    "# data_path = \"/home/shared/data_raw/LAC/runs/stereo_lights1.0_map1_preset1\"\n",
    "# data_path = \"/home/shared/data_raw/LAC/runs/full_spiral_map1_preset0\"\n",
    "data_path = \"../../../output/NavAgent/2025-05-09_05-20-06\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)\n",
    "print(f\"Num poses: {len(poses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_imgs, right_imgs = load_stereo_images(data_path)\n",
    "images = load_images(data_path, cameras=[\"FrontLeft\", \"FrontRight\"], start_frame=0, end_frame=10000)\n",
    "left_imgs = images[\"FrontLeft\"]\n",
    "right_imgs = images[\"FrontRight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = FeatureTracker(cam_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = left_imgs[100]\n",
    "\n",
    "feats = tracker.extract_feats(image)\n",
    "feats = rbd(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps = feats[\"keypoints\"]\n",
    "good_kps = kps[feats[\"keypoint_scores\"] > 0.05]\n",
    "print(f\"Num keypoints: {len(kps)}, {len(good_kps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz2d.plot_images([image])\n",
    "viz2d.plot_keypoints([kps], colors=[\"red\"], ps=10)\n",
    "viz2d.plot_keypoints([good_kps], colors=[\"lime\"], ps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature matching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stereo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 700\n",
    "\n",
    "feats1 = tracker.extract_feats(left_imgs[frame])\n",
    "feats2 = tracker.extract_feats(right_imgs[frame])\n",
    "matches = tracker.match_feats(feats1, feats2)\n",
    "\n",
    "points1 = feats1[\"keypoints\"][0][matches[:, 0]].cpu().numpy()\n",
    "points2 = feats2[\"keypoints\"][0][matches[:, 1]].cpu().numpy()\n",
    "\n",
    "viz2d.plot_images([left_imgs[frame], right_imgs[frame]], pad=0.0)\n",
    "viz2d.plot_matches(points1, points2, color=\"lime\", lw=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1 = 1300\n",
    "frame2 = 1400\n",
    "img1 = left_imgs[frame1]\n",
    "img2 = left_imgs[frame2]\n",
    "\n",
    "feats1 = tracker.extract_feats(img1)\n",
    "feats2 = tracker.extract_feats(img2)\n",
    "matches = tracker.match_feats(feats1, feats2)\n",
    "\n",
    "points1 = feats1[\"keypoints\"][0][matches[:, 0]].cpu().numpy()\n",
    "points2 = feats2[\"keypoints\"][0][matches[:, 1]].cpu().numpy()\n",
    "\n",
    "viz2d.plot_images([img1, img2])\n",
    "viz2d.plot_matches(points1, points2, lw=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGlue Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_img = left_imgs[1500]\n",
    "next_img = left_imgs[1502]\n",
    "\n",
    "prev_feats = tracker.extract_feats(prev_img)\n",
    "next_feats = tracker.extract_feats(next_img)\n",
    "\n",
    "matches = tracker.match_feats(prev_feats, next_feats)\n",
    "points_prev = prev_feats[\"keypoints\"][0][matches[:, 0]]\n",
    "points_next = next_feats[\"keypoints\"][0][matches[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = tracker.match_feats(prev_feats, next_feats, min_score=0.9)\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points0 = points_prev.cpu().numpy()\n",
    "points1 = points_next.cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(next_img, cmap=\"gray\")\n",
    "for i in range(len(matches)):\n",
    "    plt.plot([points0[i, 0], points1[i, 0]], [points0[i, 1], points1[i, 1]], color=\"lime\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV LK Optical Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opencv optical flow\n",
    "prev_img = left_imgs[1500]\n",
    "next_img = left_imgs[1502]\n",
    "\n",
    "prev_pts = kps.cpu().numpy()\n",
    "\n",
    "lk_params = dict(\n",
    "    winSize=(21, 21),\n",
    "    maxLevel=3,\n",
    "    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.03),\n",
    "    minEigThreshold=1e-4,\n",
    ")\n",
    "\n",
    "# next_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_img, next_img, prev_pts, None, **lk_params)\n",
    "next_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_img, next_img, prev_pts, None)\n",
    "next_pts_tracked = next_pts[status.squeeze() == 1]\n",
    "prev_pts_tracked = prev_pts[status.squeeze() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(next_img, cmap=\"gray\")\n",
    "for new, old in zip(next_pts_tracked, prev_pts_tracked):\n",
    "    a, b = new.ravel()\n",
    "    c, d = old.ravel()\n",
    "    plt.arrow(c, d, a - c, b - d, color=\"lime\", head_width=1, head_length=2, linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature tracker class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.slam.feature_tracker import FeatureTracker, prune_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = FeatureTracker(cam_config)\n",
    "\n",
    "start_idx = 80\n",
    "tracker.initialize(poses[start_idx], left_imgs[start_idx], right_imgs[start_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = start_idx\n",
    "n_frames = 100\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(n_frames):\n",
    "    idx += 2\n",
    "    if i % 10 == 0:\n",
    "        tracker.track_keyframe(poses[idx], left_imgs[idx], right_imgs[idx])\n",
    "    else:\n",
    "        tracker.track(left_imgs[idx])\n",
    "\n",
    "print(f\"Avg time per frame: {(time.time() - start_time) / n_frames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tracker.track_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1 = 1300\n",
    "frame2 = 1400\n",
    "img1 = left_imgs[frame1]\n",
    "img2 = left_imgs[frame2]\n",
    "\n",
    "feats1 = tracker.extract_feats(img1)\n",
    "feats2 = tracker.extract_feats(img2)\n",
    "matches = tracker.match_feats(feats1, feats2)\n",
    "\n",
    "points1 = feats1[\"keypoints\"][0][matches[:, 0]].cpu().numpy()\n",
    "points2 = feats2[\"keypoints\"][0][matches[:, 1]].cpu().numpy()\n",
    "\n",
    "viz2d.plot_images([img1, img2])\n",
    "viz2d.plot_matches(points1, points2, lw=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
