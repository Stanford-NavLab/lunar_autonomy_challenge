{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from lightglue import LightGlue, SuperPoint, viz2d, match_pair\n",
    "from lightglue.utils import rbd\n",
    "\n",
    "from lac.perception.depth import project_pixel_to_rover\n",
    "from lac.utils.frames import apply_transform\n",
    "from lac.utils.plotting import plot_3d_points, plot_surface, plot_poses, plot_path_3d\n",
    "from lac.util import load_data, grayscale_to_3ch_tensor\n",
    "from lac.params import LAC_BASE_PATH, DT\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(LAC_BASE_PATH) / \"output/DataCollectionAgent/map1_preset0_stereo_lights1.0\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)\n",
    "print(f\"Num poses: {len(poses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_imgs = {}\n",
    "right_imgs = {}\n",
    "\n",
    "for img_name in os.listdir(data_path / \"FrontLeft\"):\n",
    "    left_imgs[int(img_name.split(\".\")[0])] = cv2.imread(\n",
    "        str(data_path / \"FrontLeft\" / img_name), cv2.IMREAD_GRAYSCALE\n",
    "    )\n",
    "\n",
    "for img_name in os.listdir(data_path / \"FrontRight\"):\n",
    "    right_imgs[int(img_name.split(\".\")[0])] = cv2.imread(\n",
    "        str(data_path / \"FrontRight\" / img_name), cv2.IMREAD_GRAYSCALE\n",
    "    )\n",
    "\n",
    "assert len(left_imgs.keys()) == len(right_imgs.keys())\n",
    "img_idxs = sorted(left_imgs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = SuperPoint(max_num_keypoints=2048).eval().cuda()\n",
    "matcher = LightGlue(features=\"superpoint\").eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = left_imgs[1500]\n",
    "\n",
    "feats = extractor.extract(grayscale_to_3ch_tensor(image).cuda())\n",
    "feats = rbd(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps = feats[\"keypoints\"]\n",
    "good_kps = kps[feats[\"keypoint_scores\"] > 0.05]\n",
    "print(f\"Num keypoints: {len(kps)}, {len(good_kps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz2d.plot_images([image])\n",
    "viz2d.plot_keypoints([kps], ps=10)\n",
    "viz2d.plot_keypoints([good_kps], colors=[\"red\"], ps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGlue Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_img = left_imgs[1500]\n",
    "next_img = left_imgs[1502]\n",
    "\n",
    "feats0, feats1, matches01 = match_pair(\n",
    "    extractor,\n",
    "    matcher,\n",
    "    grayscale_to_3ch_tensor(prev_img).cuda(),\n",
    "    grayscale_to_3ch_tensor(next_img).cuda(),\n",
    ")\n",
    "matches = matches01[\"matches\"]  # indices with shape (K,2)\n",
    "points0 = feats0[\"keypoints\"][matches[..., 0]]  # coordinates in image #0, shape (K,2)\n",
    "points1 = feats1[\"keypoints\"][matches[..., 1]]  # coordinates in image #1, shape (K,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(next_img, cmap=\"gray\")\n",
    "for i in range(len(matches)):\n",
    "    plt.plot([points0[i, 0], points1[i, 0]], [points0[i, 1], points1[i, 1]], color=\"lime\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV LK Optical Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opencv optical flow\n",
    "prev_img = left_imgs[1500]\n",
    "next_img = left_imgs[1502]\n",
    "\n",
    "prev_pts = kps.cpu().numpy()\n",
    "\n",
    "lk_params = dict(\n",
    "    winSize=(15, 15),\n",
    "    maxLevel=3,\n",
    "    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    ")\n",
    "\n",
    "next_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_img, next_img, prev_pts, None)\n",
    "next_pts_tracked = next_pts[status.squeeze() == 1]\n",
    "prev_pts_tracked = prev_pts[status.squeeze() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(next_img, cmap=\"gray\")\n",
    "for new, old in zip(next_pts_tracked, prev_pts_tracked):\n",
    "    a, b = new.ravel()\n",
    "    c, d = old.ravel()\n",
    "    plt.arrow(c, d, a - c, b - d, color=\"lime\", head_width=1, head_length=2, linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_feats = extractor.extract(grayscale_to_3ch_tensor(prev_img).cuda())\n",
    "\n",
    "tracked_feats = prev_feats.copy()\n",
    "tracked_feats[\"keypoints\"] = torch.from_numpy(next_pts_tracked).unsqueeze(0).cuda()\n",
    "tracked_feats[\"keypoint_scores\"] = prev_feats[\"keypoint_scores\"][0][\n",
    "    status.squeeze() == 1\n",
    "].unsqueeze(0)\n",
    "tracked_feats[\"descriptors\"] = prev_feats[\"descriptors\"][0][status.squeeze() == 1].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_feats = extractor.extract(grayscale_to_3ch_tensor(next_img).cuda())\n",
    "matches = matcher({\"image0\": tracked_feats, \"image1\": next_feats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = rbd(matches)[\"matches\"]  # indices with shape (K,2)\n",
    "points0 = rbd(tracked_feats)[\"keypoints\"][matches[..., 0]]  # coordinates in image #0, shape (K,2)\n",
    "points1 = rbd(next_feats)[\"keypoints\"][matches[..., 1]]  # coordinates in image #1, shape (K,2)\n",
    "\n",
    "points0 = points0.cpu().numpy()\n",
    "points1 = points1.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.localization.slam.feature_tracker import prune_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_features(next_feats, matches[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_feats[\"keypoints\"][0, matches[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(next_img, cmap=\"gray\")\n",
    "for i in range(len(matches)):\n",
    "    plt.plot([points0[i, 0], points1[i, 0]], [points0[i, 1], points1[i, 1]], color=\"lime\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
