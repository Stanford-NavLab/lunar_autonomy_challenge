{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from gtsam.symbol_shorthand import X\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lac.slam.feature_tracker import FeatureTracker, prune_features\n",
    "from lac.perception.segmentation import UnetSegmentation\n",
    "from lac.utils.plotting import plot_poses, plot_surface, plot_3d_points\n",
    "from lac.util import load_data, load_stereo_images\n",
    "from lac.utils.visualization import overlay_mask\n",
    "from lac.params import LAC_BASE_PATH\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data logs\n",
    "data_path = Path(\"/home/shared/data_raw/LAC/segmentation/slam_map1_preset1_teleop\")\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)\n",
    "print(f\"Loaded {len(poses)} poses\")\n",
    "\n",
    "# Load the images\n",
    "left_imgs, right_imgs = load_stereo_images(data_path)\n",
    "\n",
    "# Load the ground truth map\n",
    "map = np.load(\n",
    "    \"/home/shared/data_raw/LAC/heightmaps/competition/Moon_Map_01_preset_1.dat\",\n",
    "    allow_pickle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = UnetSegmentation()\n",
    "feature_tracker = FeatureTracker(cam_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frontend:\n",
    "\n",
    "- Run both segmentation and feature extraction on left and right images\n",
    "- Triangulate feature matches. For keypoints labeled as rock, group them together\n",
    "\n",
    "Rock map:\n",
    "\n",
    "- Each rock has a set of world points with associated descriptors (these descriptors should probably also be associated with a viewing direction since the apperance of a rock can change with viewing direction)\n",
    "-\n",
    "\n",
    "Graph SLAM:\n",
    "\n",
    "- In the graph, we have a landmark for each rock corresponding to its centroid point\n",
    "- For each keyframe, we determine the observed pixel centroid of the rock based on segementation outputs, and use that to add reprojection factors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection\n",
    "\n",
    "For each left, right image pair:\n",
    "\n",
    "- For each image: a list of rock detections, where each detection is (pixel mask, pixel centroid, detected keypoints, keypoint descriptors, descriptor scores)\n",
    "- Triangulated 3D points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_FRAME = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME = 200\n",
    "left_image = left_imgs[FRAME]\n",
    "right_image = right_imgs[FRAME]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 10))\n",
    "ax[0].imshow(left_image, cmap=\"gray\")\n",
    "ax[1].imshow(right_image, cmap=\"gray\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_masks, left_labels = segmentation.segment_rocks(left_image)\n",
    "right_masks, right_labels = segmentation.segment_rocks(right_image)\n",
    "left_full_mask = np.clip(left_labels, 0, 1).astype(np.uint8)\n",
    "right_full_mask = np.clip(right_labels, 0, 1).astype(np.uint8)\n",
    "\n",
    "left_seg_overlay = overlay_mask(left_image, left_full_mask, color=(1, 0, 0))\n",
    "right_seg_overlay = overlay_mask(right_image, right_full_mask, color=(1, 0, 0))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 10))\n",
    "ax[0].imshow(left_seg_overlay)\n",
    "ax[1].imshow(right_seg_overlay)\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_feats, right_feats, matches, depths = feature_tracker.process_stereo(left_image, right_image)\n",
    "\n",
    "left_matched_feats = prune_features(left_feats, matches[:, 0])\n",
    "left_matched_pts = left_matched_feats[\"keypoints\"][0]\n",
    "right_matched_feats = prune_features(right_feats, matches[:, 1])\n",
    "right_matched_pts = right_matched_feats[\"keypoints\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to points that are within segmentations\n",
    "\n",
    "# Dilate the masks\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "left_full_mask_dilated = cv2.dilate(left_full_mask, kernel, iterations=1)\n",
    "right_full_mask_dilated = cv2.dilate(right_full_mask, kernel, iterations=1)\n",
    "\n",
    "rock_pt_idxs = []\n",
    "\n",
    "for i in range(len(left_matched_pts)):\n",
    "    x_left, y_left = left_matched_pts[i]\n",
    "    x_right, y_right = right_matched_pts[i]\n",
    "    if (\n",
    "        left_full_mask_dilated[int(y_left), int(x_left)]\n",
    "        and right_full_mask_dilated[int(y_right), int(x_right)]\n",
    "    ):\n",
    "        rock_pt_idxs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_rock_matched_pts = left_matched_pts[rock_pt_idxs]\n",
    "right_rock_matched_pts = right_matched_pts[rock_pt_idxs]\n",
    "depths_rock_matched = depths[rock_pt_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightglue import viz2d\n",
    "\n",
    "viz2d.plot_images([left_seg_overlay, right_seg_overlay])\n",
    "viz2d.plot_matches(left_rock_matched_pts, right_rock_matched_pts, color=\"lime\", lw=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_points = feature_tracker.project_stereo(\n",
    "    poses[FRAME], left_rock_matched_pts, depths_rock_matched\n",
    ")\n",
    "plot_3d_points(rock_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.perception.segmentation import SemanticClasses\n",
    "from lac.perception.segmentation_util import dilate_mask\n",
    "\n",
    "left_pred = segmentation.predict(left_image)\n",
    "left_rock_mask = (left_pred == SemanticClasses.ROCKS.value).astype(np.uint8)\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "left_rock_mask = cv2.dilate(left_rock_mask, kernel, iterations=1)\n",
    "\n",
    "num_labels, labels = cv2.connectedComponents(left_rock_mask)\n",
    "\n",
    "rock_pt_idxs = {}\n",
    "MAX_DEPTH = 5.0\n",
    "\n",
    "for i in range(len(left_matched_pts)):\n",
    "    if depths[i] > MAX_DEPTH:\n",
    "        continue\n",
    "    x_left, y_left = left_matched_pts[i]\n",
    "    x_right, y_right = right_matched_pts[i]\n",
    "    id = labels[int(y_left), int(x_left)]\n",
    "    if (\n",
    "        left_rock_mask[int(y_left), int(x_left)] != 0\n",
    "        and right_full_mask_dilated[int(y_right), int(x_right)] != 0\n",
    "    ):\n",
    "        if id not in rock_pt_idxs:\n",
    "            rock_pt_idxs[id] = []\n",
    "        rock_pt_idxs[id].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightglue import viz2d\n",
    "\n",
    "viz2d.plot_images([left_seg_overlay, right_seg_overlay])\n",
    "for key, val in rock_pt_idxs.items():\n",
    "    left_pts = left_matched_pts[val]\n",
    "    right_pts = right_matched_pts[val]\n",
    "    newcolor = np.random.rand(3)\n",
    "    viz2d.plot_matches(left_pts, right_pts, color=newcolor, lw=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from norfair import Detection, Tracker\n",
    "import plotly.graph_objects as go\n",
    "from lac.perception.depth import stereo_depth_from_segmentation, project_pixel_to_world\n",
    "from lac.params import STEREO_BASELINE, FL_X\n",
    "from lac.utils.plotting import plot_rock_map\n",
    "from lac.utils.visualization import int_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idxs = sorted(left_imgs.keys())\n",
    "tracker = Tracker(distance_function=\"euclidean\", distance_threshold=100, hit_counter_max=5)\n",
    "rock_detections = {}  # id -> (3d point, pixel, frame_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END_FRAME = img_idxs[-1]\n",
    "END_FRAME = 200\n",
    "for frame in tqdm(range(2, END_FRAME, 2)):\n",
    "    left_seg_masks, left_seg_labels = segmentation.segment_rocks(left_imgs[frame])\n",
    "    right_seg_masks, right_seg_labels = segmentation.segment_rocks(right_imgs[frame])\n",
    "    left_seg_full_mask = np.clip(left_seg_labels, 0, 1)\n",
    "\n",
    "    stereo_depth_results = stereo_depth_from_segmentation(\n",
    "        left_seg_masks, right_seg_masks, STEREO_BASELINE, FL_X\n",
    "    )\n",
    "\n",
    "    detections = []\n",
    "    centroids = []\n",
    "    for result in stereo_depth_results:\n",
    "        centroid = result[\"left_centroid\"]\n",
    "        depth = result[\"depth\"]\n",
    "        if depth < 5.0:\n",
    "            rock_point_world_frame = project_pixel_to_world(\n",
    "                poses[frame], centroid, result[\"depth\"], \"FrontLeft\", cam_config\n",
    "            )\n",
    "            centroids.append(centroid)\n",
    "            detections.append(Detection(points=centroid, data=rock_point_world_frame))\n",
    "    tracked_objects = tracker.update(detections)\n",
    "\n",
    "    for rock in tracked_objects:\n",
    "        centroid_pixel = rock.last_detection.points[0]\n",
    "        if rock.id not in rock_detections:\n",
    "            rock_detections[rock.id] = {\"frame\": [], \"points\": [], \"pixels\": []}\n",
    "        rock_detections[rock.id][\"frame\"].append(frame)\n",
    "        rock_detections[rock.id][\"points\"].append(rock.last_detection.data)\n",
    "        rock_detections[rock.id][\"pixels\"].append(centroid_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig = plot_rock_map(map, fig=fig)\n",
    "fig = plot_poses(poses, fig=fig, no_axes=True, color=\"black\")\n",
    "for id, detections in rock_detections.items():\n",
    "    points = np.array(detections[\"points\"])\n",
    "    fig = plot_3d_points(\n",
    "        points, fig=fig, color=int_to_color(id, hex=True), markersize=2, name=f\"rock_{id}\"\n",
    "    )\n",
    "    avg_point = np.median(points, axis=0)\n",
    "    fig = plot_3d_points(\n",
    "        avg_point[None, :],\n",
    "        fig=fig,\n",
    "        color=int_to_color(id, hex=True),\n",
    "        markersize=5,\n",
    "        name=f\"rock_{id}_avg\",\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtsam\n",
    "from gtsam.symbol_shorthand import X, L\n",
    "\n",
    "from lac.slam.visual_odometry import StereoVisualOdometry\n",
    "from lac.slam.slam import ROVER_T_CAM\n",
    "from lac.params import FL_X, FL_Y, IMG_HEIGHT, IMG_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo = StereoVisualOdometry(cam_config)\n",
    "START_FRAME = 80\n",
    "svo.initialize(initial_pose, left_imgs[START_FRAME], right_imgs[START_FRAME])\n",
    "\n",
    "# Pre-process the VO\n",
    "svo_poses = [initial_pose]\n",
    "pose_deltas = []\n",
    "\n",
    "END_FRAME = 4500\n",
    "\n",
    "for idx in tqdm(np.arange(START_FRAME + 2, END_FRAME, 2)):\n",
    "    svo.track(left_imgs[idx], right_imgs[idx])\n",
    "    svo_poses.append(svo.rover_pose)\n",
    "    pose_deltas.append(svo.pose_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXEL_NOISE = gtsam.noiseModel.Isotropic.Sigma(2, 5.0)\n",
    "K = gtsam.Cal3_S2(FL_X, FL_Y, 0.0, IMG_WIDTH / 2, IMG_HEIGHT / 2)\n",
    "\n",
    "svo_pose_sigma = 1e-2 * np.ones(6)\n",
    "svo_pose_noise = gtsam.noiseModel.Diagonal.Sigmas(svo_pose_sigma)\n",
    "\n",
    "graph = gtsam.NonlinearFactorGraph()\n",
    "values = gtsam.Values()\n",
    "\n",
    "values.insert(X(0), gtsam.Pose3(initial_pose))\n",
    "graph.add(gtsam.NonlinearEqualityPose3(X(0), gtsam.Pose3(initial_pose)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_to_i = {0: 0}\n",
    "\n",
    "# Add poses and VO odometry\n",
    "i = 1\n",
    "for frame in range(START_FRAME, END_FRAME - 2, 2):\n",
    "    frame_to_i[frame] = i\n",
    "    # values.insert(X(i), gtsam.Pose3(poses[frame]))\n",
    "    values.insert(X(i), gtsam.Pose3(svo_poses[i]))\n",
    "    graph.push_back(\n",
    "        gtsam.BetweenFactorPose3(X(i - 1), X(i), gtsam.Pose3(pose_deltas[i - 1]), svo_pose_noise)\n",
    "    )\n",
    "    i += 1\n",
    "\n",
    "active_rock_ids = {}\n",
    "rock_id_count = 0\n",
    "\n",
    "# Add rock landmarks and observations\n",
    "for id, detections in rock_detections.items():\n",
    "    points = np.array(detections[\"points\"])\n",
    "    pixels = np.array(detections[\"pixels\"])\n",
    "    frames = np.array(detections[\"frame\"])\n",
    "    avg_point = np.median(points, axis=0)\n",
    "\n",
    "    for j in range(len(frames)):\n",
    "        if frames[j] not in frame_to_i:\n",
    "            continue\n",
    "\n",
    "        if id not in active_rock_ids:\n",
    "            active_rock_ids[id] = rock_id_count\n",
    "            rock_id_count += 1\n",
    "            values.insert(L(active_rock_ids[id]), avg_point)\n",
    "\n",
    "        i = frame_to_i[frames[j]]\n",
    "        graph.add(\n",
    "            gtsam.GenericProjectionFactorCal3_S2(\n",
    "                pixels[j], PIXEL_NOISE, X(i), L(active_rock_ids[id]), K, ROVER_T_CAM\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = gtsam.LevenbergMarquardtParams()\n",
    "params.setVerbosity(\"TERMINATION\")\n",
    "optimizer = gtsam.LevenbergMarquardtOptimizer(graph, values, params)\n",
    "result = optimizer.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_poses = [result.atPose3(X(k)).matrix() for k in range(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(poses[80:END_FRAME], no_axes=True, color=\"black\", name=\"Ground Truth\")\n",
    "fig = plot_poses(opt_poses, no_axes=True, fig=fig, color=\"green\", name=\"Opt\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
