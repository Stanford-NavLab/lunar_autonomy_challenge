{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "from lac.utils.plotting import plot_path_3d, plot_3d_points\n",
    "from lac.localization.mono_vo import MonoVisualOdometry\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature detection/matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/shared/data_raw/LAC/segmentation/slam_map1_preset1_teleop\"\n",
    "\n",
    "i = 100\n",
    "I1_path = os.path.join(data_path, \"FrontLeft\", f\"{i}.png\")\n",
    "I2_path = os.path.join(data_path, \"FrontLeft\", f\"{i + 2}.png\")\n",
    "I1 = cv.imread(I1_path, cv.IMREAD_GRAYSCALE)\n",
    "I2 = cv.imread(I2_path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Plot images side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "ax[0].imshow(I1, cmap=\"gray\")\n",
    "ax[1].imshow(I2, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGlue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightglue import LightGlue, SuperPoint, DISK, SIFT, ALIKED, DoGHardNet\n",
    "from lightglue.utils import load_image, rbd\n",
    "from lightglue import match_pair, viz2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SuperPoint+LightGlue\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().cuda()  # load the extractor\n",
    "matcher = LightGlue(features=\"superpoint\").eval().cuda()  # load the matcher\n",
    "\n",
    "# load each image as a torch.Tensor on GPU with shape (3,H,W), normalized in [0,1]\n",
    "image0 = load_image(I1_path).cuda()\n",
    "image1 = load_image(I2_path).cuda()\n",
    "\n",
    "feats0, feats1, matches01 = match_pair(extractor, matcher, image0, image1)\n",
    "matches = matches01[\"matches\"]  # indices with shape (K,2)\n",
    "points0 = feats0[\"keypoints\"][matches[..., 0]]  # coordinates in image #0, shape (K,2)\n",
    "points1 = feats1[\"keypoints\"][matches[..., 1]]  # coordinates in image #1, shape (K,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_matches(points0, points1, color=\"lime\", lw=0.2)\n",
    "viz2d.add_text(0, f\"Stop after {matches01['stop']} layers\", fs=20)\n",
    "\n",
    "kpc0, kpc1 = viz2d.cm_prune(matches01[\"prune0\"]), viz2d.cm_prune(matches01[\"prune1\"])\n",
    "viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_keypoints([feats0[\"keypoints\"], feats1[\"keypoints\"]], colors=[kpc0, kpc1], ps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORB (left) vs FAST (right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_detector = cv.FastFeatureDetector_create(threshold=25, nonmaxSuppression=True)\n",
    "orb_detector = cv.ORB_create(nfeatures=1000)\n",
    "orb_kp = orb_detector.detect(I1)\n",
    "orb_kp, orb_des = orb_detector.compute(I1, orb_kp)\n",
    "\n",
    "fast_kp = fast_detector.detect(I1)\n",
    "\n",
    "I1_orb = cv.drawKeypoints(I1, orb_kp, None, color=(0, 255, 0), flags=0)\n",
    "I1_fast = cv.drawKeypoints(I1, fast_kp, None, color=(0, 255, 0), flags=0)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "ax[0].imshow(I1_orb)\n",
    "ax[1].imshow(I1_fast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I2_fast = cv.drawKeypoints(I2, fast_detector.detect(I2), None, color=(0, 255, 0), flags=0)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "ax[0].imshow(I1_fast)\n",
    "ax[1].imshow(I2_fast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking (pyslam-based VO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.perception.vision import StereoVIO\n",
    "from lac.params import FL_X, STEREO_BASELINE, CAMERA_INTRINSICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svio = StereoVIO(FL_X, STEREO_BASELINE)\n",
    "\n",
    "data_path = os.path.expanduser(\"~/LunarAutonomyChallenge/output/NavAgent/map1_preset4_gtnav_steer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the first stereo pair to initialize depths\n",
    "I1_path = os.path.join(data_path, \"FrontLeft\", \"100.png\")\n",
    "I2_path = os.path.join(data_path, \"FrontRight\", \"100.png\")\n",
    "I1 = cv.imread(I1_path, cv.IMREAD_GRAYSCALE)\n",
    "I2 = cv.imread(I2_path, cv.IMREAD_GRAYSCALE)\n",
    "svio.process_stereo_pair(I1, I2)\n",
    "\n",
    "# Track from frame to frame\n",
    "for i in tqdm(np.arange(102, 200, 2)):\n",
    "    I1_path = os.path.join(data_path, \"FrontLeft\", f\"{i}.png\")\n",
    "    I1 = cv.imread(I1_path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Estimate relative pose\n",
    "    rvec, tvec = svio.track_frame(I1, CAMERA_INTRINSICS)\n",
    "    print(f\"Frame {i}: rvec={rvec.ravel()}, tvec={tvec.ravel()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mono VO class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters ---------------------------------------------------------------\n",
    "\n",
    "data_path = os.path.expanduser(\n",
    "    \"~/LunarAutonomyChallenge/output/LocalizationAgent/map1_preset0_4m_spiral\"\n",
    ")\n",
    "img_path = f\"{data_path}/FrontLeft\"\n",
    "json_data = json.load(open(f\"{data_path}/data_log.json\"))\n",
    "initial_pose = np.array(json_data[\"initial_pose\"])  # TODO: initialize with initial pose\n",
    "\n",
    "trajlen = 1000\n",
    "\n",
    "# for KITTI\n",
    "focal = 915.0\n",
    "pp = (1280 / 2, 720 / 2)  # principal point\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(\n",
    "    winSize=(21, 21), criteria=(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 30, 0.01)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "positions = []\n",
    "for frame in json_data[\"frames\"]:\n",
    "    poses.append(np.array(frame[\"pose\"]))\n",
    "    positions.append(np.array(frame[\"pose\"])[:3, 3])\n",
    "positions = np.array(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo = MonoVisualOdometry(img_path, poses, focal, pp, lk_params)\n",
    "# vo.R = initial_pose[:3, :3]\n",
    "# vo.t = initial_pose[:3, 3][:,None]\n",
    "vo.initialize_pose(initial_pose[:3, :3], initial_pose[:3, 3][:, None])\n",
    "vo.init_frame(id=84)\n",
    "vo_traj = np.zeros((trajlen, 3))\n",
    "\n",
    "for i in tqdm(range(trajlen)):\n",
    "    vo.process_frame()\n",
    "    vo_traj[i, :] = vo.get_mono_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_path_3d(vo_traj, color=\"orange\", name=\"VO\")\n",
    "fig = plot_path_3d(positions[:trajlen], color=\"blue\", name=\"ground truth\", fig=fig)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
