{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual SLAM\n",
    "\n",
    "1. Initialization: At first frame, initialize map with 3D points from stereo.\n",
    "2. Tracking:\n",
    "   - at frame i+1, match keypoints between i and i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from lightglue import LightGlue, SuperPoint\n",
    "from lightglue.utils import rbd\n",
    "\n",
    "from lac.slam.feature_tracker import FeatureTracker\n",
    "from lac.perception.depth import project_pixel_to_rover\n",
    "from lac.utils.frames import apply_transform\n",
    "from lac.utils.plotting import plot_3d_points, plot_surface, plot_poses, plot_path_3d\n",
    "from lac.util import load_data, load_stereo_images\n",
    "from lac.params import LAC_BASE_PATH, DT\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(LAC_BASE_PATH) / \"output/DataCollectionAgent/slam_map1_preset1_teleop\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)\n",
    "print(f\"Num poses: {len(poses)}\")\n",
    "\n",
    "# Load the images\n",
    "left_imgs, right_imgs = load_stereo_images(data_path)\n",
    "\n",
    "map = np.load(\n",
    "    Path(LAC_BASE_PATH) / \"data/heightmaps/competition/Moon_Map_01_preset_0.dat\",\n",
    "    allow_pickle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idxs = sorted(list(left_imgs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_surface(map)\n",
    "fig = plot_poses(poses[::20], fig=fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stereo (PnP) VO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.slam.visual_odometry import StereoVisualOdometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo = StereoVisualOdometry(cam_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 80\n",
    "svo.initialize(poses[start_idx], left_imgs[start_idx], right_imgs[start_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_poses = [poses[start_idx]]\n",
    "pose_deltas = []\n",
    "\n",
    "end_idx = img_idxs[-1]\n",
    "# end_idx = 2000\n",
    "\n",
    "for idx in tqdm(np.arange(start_idx + 2, end_idx, 2)):\n",
    "    svo.track(left_imgs[idx], right_imgs[idx])\n",
    "    svo_poses.append(svo.rover_pose)\n",
    "    pose_deltas.append(svo.pose_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(poses, no_axes=True, color=\"black\", name=\"Ground Truth\")\n",
    "fig = plot_poses(svo_poses, no_axes=True, fig=fig, color=\"red\", name=\"Stereo (PnP) VO\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"vo_traj.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the poses for poses where XY are within 0.01m of each other\n",
    "positions_2d = np.array([pose[:2, 3] for pose in svo_poses])\n",
    "\n",
    "\n",
    "def compute_distance_matrix(points):\n",
    "    # Compute the squared Euclidean distance matrix\n",
    "    diff = points[:, np.newaxis, :] - points[np.newaxis, :, :]\n",
    "    dist_matrix = np.sqrt(np.sum(diff**2, axis=2))\n",
    "    return dist_matrix\n",
    "\n",
    "\n",
    "dist_matrix = compute_distance_matrix(positions_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the indices of the pairs of points that are within 0.01m\n",
    "threshold = 0.01\n",
    "indices = np.argwhere(dist_matrix < threshold)\n",
    "# Filter out pairs where the indices are the same\n",
    "indices = indices[indices[:, 0] != indices[:, 1]]\n",
    "# Remove duplicates (i.e., (i, j) and (j, i))\n",
    "unique_indices = set()\n",
    "for i, j in indices:\n",
    "    if abs(i - j) > 100 and (j, i) not in unique_indices:\n",
    "        unique_indices.add((i, j))\n",
    "# Convert the set back to a list of tuples\n",
    "unique_indices = list(unique_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = plot_poses(poses, no_axes=True, color=\"black\", name=\"Ground Truth\")\n",
    "fig = plot_poses(svo_poses, no_axes=True, fig=fig, color=\"red\", name=\"Stereo (PnP) VO\")\n",
    "# Add the lines between the points\n",
    "for i, j in unique_indices:\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[svo_poses[i][0, 3], svo_poses[j][0, 3]],\n",
    "            y=[svo_poses[i][1, 3], svo_poses[j][1, 3]],\n",
    "            z=[svo_poses[i][2, 3], svo_poses[j][2, 3]],\n",
    "            mode=\"markers+lines\",\n",
    "            marker=dict(size=5, color=\"blue\"),\n",
    "            line=dict(color=\"blue\", width=5),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtsam\n",
    "from gtsam.symbol_shorthand import B, V, X\n",
    "\n",
    "graph = gtsam.NonlinearFactorGraph()\n",
    "values = gtsam.Values()\n",
    "\n",
    "svo_pose_sigma = 1e-2 * np.ones(6)\n",
    "svo_pose_noise = gtsam.noiseModel.Diagonal.Sigmas(svo_pose_sigma)\n",
    "\n",
    "values.insert(X(0), gtsam.Pose3(svo_poses[0]))\n",
    "graph.add(gtsam.NonlinearEqualityPose3(X(0), gtsam.Pose3(svo_poses[0])))\n",
    "\n",
    "for i in range(1, len(svo_poses)):\n",
    "    values.insert(X(i), gtsam.Pose3(svo_poses[i]))\n",
    "    graph.push_back(\n",
    "        gtsam.BetweenFactorPose3(X(i - 1), X(i), gtsam.Pose3(pose_deltas[i - 1]), svo_pose_noise)\n",
    "    )\n",
    "\n",
    "translation_only_noise = gtsam.noiseModel.Diagonal.Sigmas(np.array([1e6, 1e6, 1e6, 0.1, 0.1, 0.1]))\n",
    "for i, j in unique_indices:\n",
    "    # Add a prior on the relative pose between the two poses\n",
    "    graph.push_back(gtsam.BetweenFactorPose3(X(i), X(j), gtsam.Pose3(np.eye(4)), svo_pose_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = gtsam.LevenbergMarquardtParams()\n",
    "optimizer = gtsam.LevenbergMarquardtOptimizer(graph, values, params)\n",
    "result = optimizer.optimize()\n",
    "\n",
    "opt_poses = [result.atPose3(X(i)).matrix() for i in range(len(svo_poses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(poses, no_axes=True, color=\"black\", name=\"Ground Truth\")\n",
    "fig = plot_poses(svo_poses, no_axes=True, fig=fig, color=\"red\", name=\"Stereo (PnP) VO\")\n",
    "fig = plot_poses(opt_poses, no_axes=True, fig=fig, color=\"green\", name=\"Stereo (PnP) VO\")\n",
    "for i, j in unique_indices:\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[opt_poses[i][0, 3], opt_poses[j][0, 3]],\n",
    "            y=[opt_poses[i][1, 3], opt_poses[j][1, 3]],\n",
    "            z=[opt_poses[i][2, 3], opt_poses[j][2, 3]],\n",
    "            mode=\"markers+lines\",\n",
    "            marker=dict(size=5, color=\"blue\"),\n",
    "            line=dict(color=\"blue\", width=5),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, the XYs will change during optimization, so we need a global loss over the whole trajectory\n",
    "that enforces Z to be close when XY is close. We could do this through an energy term such as:\n",
    "$$ E*{\\text{smooth}} = \\sum*{i,j} w(\\| (x_i, y_i) - (x_j, y_j) \\|)(z_i - z_j)^2 $$\n",
    "where $w(\\cdot)$ is a kernel (e.g. Gaussian) that assigns high weight when xy distance is small and quickly\n",
    "decays when distance exceeds a threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loosely coupled fusion with IMU odometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.localization.imu_recovery import ImuEstimator\n",
    "from lac.utils.frames import invert_transform_mat\n",
    "\n",
    "imu_estimator = ImuEstimator(initial_pose)\n",
    "imu_recovery_poses = [initial_pose]\n",
    "imu_recovery_deltas = []\n",
    "gt_pose_deltas = []\n",
    "\n",
    "for i in tqdm(range(len(imu_data))):\n",
    "    imu_estimator.update(imu_data[i], exact=False)\n",
    "    imu_recovery_poses.append(imu_estimator.get_pose())\n",
    "    imu_recovery_deltas.append(imu_estimator.get_pose_delta())\n",
    "    gt_pose_deltas.append(poses[i + 1] @ invert_transform_mat(poses[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(svo_poses), len(pose_deltas), len(imu_recovery_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtsam\n",
    "from gtsam.symbol_shorthand import B, V, X\n",
    "\n",
    "graph = gtsam.NonlinearFactorGraph()\n",
    "values = gtsam.Values()\n",
    "\n",
    "svo_pose_sigma = 1e-2 * np.ones(6)\n",
    "svo_pose_noise = gtsam.noiseModel.Diagonal.Sigmas(svo_pose_sigma)\n",
    "imu_pose_sigma = 1e-2 * np.ones(6)\n",
    "imu_pose_noise = gtsam.noiseModel.Diagonal.Sigmas(imu_pose_sigma)\n",
    "\n",
    "values.insert(X(0), gtsam.Pose3(svo_poses[0]))\n",
    "graph.add(gtsam.NonlinearEqualityPose3(X(0), gtsam.Pose3(svo_poses[0])))\n",
    "\n",
    "for i in range(1, len(svo_poses)):\n",
    "    values.insert(X(i), gtsam.Pose3(svo_poses[i]))\n",
    "    graph.push_back(\n",
    "        gtsam.BetweenFactorPose3(X(i - 1), X(i), gtsam.Pose3(pose_deltas[i - 1]), svo_pose_noise)\n",
    "    )\n",
    "    step = 2 * i + start_idx - 1\n",
    "    imu_delta = imu_recovery_deltas[step] @ imu_recovery_deltas[step - 1]\n",
    "    graph.push_back(\n",
    "        gtsam.BetweenFactorPose3(X(i - 1), X(i), gtsam.Pose3(imu_delta), imu_pose_noise)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = gtsam.LevenbergMarquardtParams()\n",
    "optimizer = gtsam.LevenbergMarquardtOptimizer(graph, values, params)\n",
    "result = optimizer.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_poses = []\n",
    "for i in range(len(svo_poses)):\n",
    "    opt_poses.append(result.atPose3(X(i)).matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(poses, no_axes=True, color=\"black\", name=\"Ground Truth\")\n",
    "fig = plot_poses(svo_poses, no_axes=True, fig=fig, color=\"red\", name=\"Stereo (PnP) VO\")\n",
    "fig = plot_poses(opt_poses, no_axes=True, fig=fig, color=\"green\", name=\"Stereo (PnP) VO\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"stereo_pnp_vo_full_spiral.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SymForce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import symforce\n",
    "\n",
    "try:\n",
    "    symforce.set_epsilon_to_symbol()\n",
    "except symforce.AlreadyUsedEpsilon:\n",
    "    print(\"Already set symforce epsilon\")\n",
    "    pass\n",
    "\n",
    "from lac.localization.factor_graph import FactorGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.localization.imu_recovery import ImuEstimator\n",
    "from lac.utils.frames import invert_transform_mat\n",
    "\n",
    "imu_estimator = ImuEstimator(initial_pose)\n",
    "imu_recovery_poses = [initial_pose]\n",
    "imu_recovery_deltas = []\n",
    "gt_pose_deltas = []\n",
    "\n",
    "for i in tqdm(range(len(imu_data))):\n",
    "    imu_estimator.update(imu_data[i], exact=False)\n",
    "    imu_recovery_poses.append(imu_estimator.get_pose())\n",
    "    imu_recovery_deltas.append(imu_estimator.get_pose_delta())\n",
    "    gt_pose_deltas.append(poses[i + 1] @ invert_transform_mat(poses[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imu_recovery_deltas), len(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = FeatureTracker(cam_config)\n",
    "graph = FactorGraph()\n",
    "\n",
    "START_FRAME = 80\n",
    "tracker.initialize(initial_pose, left_imgs[START_FRAME], right_imgs[START_FRAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "UPDATE_RATE = 10\n",
    "WINDOW_SIZE = 20\n",
    "\n",
    "curr_pose = initial_pose\n",
    "graph.add_pose(0, initial_pose)\n",
    "\n",
    "# i is step which is 0 for initial and starts at 1 for the first run_step call\n",
    "for i in tqdm(range(1, N)):\n",
    "    if i % UPDATE_RATE == 0:\n",
    "        noisy_pose = poses[i].copy()\n",
    "        noisy_pose[:3, 3] = noisy_pose[:3, 3] + np.random.normal(0, 0.1, 3)\n",
    "        graph.add_pose(i, poses[i])\n",
    "        # graph.add_pose(i, imu_recovery_poses[i])\n",
    "\n",
    "    # Add IMU factors\n",
    "    # if i > 1:\n",
    "    #     graph.add_accel_factor(i, imu_data[i - 1][:3])\n",
    "    # graph.add_gyro_factor(i, imu_data[i - 1][3:])\n",
    "\n",
    "    # Add vision factors\n",
    "    if i % 2 == 0 and i > START_FRAME:\n",
    "        if i % 10 == 0:\n",
    "            tracker.track_keyframe(poses[i], left_imgs[i], right_imgs[i])\n",
    "        else:\n",
    "            tracker.track(left_imgs[i])\n",
    "\n",
    "        if i % UPDATE_RATE == 0:\n",
    "            for k in range(len(tracker.track_ids)):\n",
    "                graph.add_reprojection_factor(\n",
    "                    i, tracker.prev_pts[k], tracker.world_points[k], tracker.track_ids[k]\n",
    "                )\n",
    "\n",
    "    # Sliding window optimization\n",
    "    # if i % UPDATE_RATE == 0:\n",
    "    #     result = graph.optimize(window=(i - UPDATE_RATE, i))\n",
    "    #     curr_pose = graph.get_pose(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch optimization\n",
    "result = graph.optimize(verbose=True)\n",
    "fgo_poses = graph.get_all_poses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(poses[:N], no_axes=True, color=\"black\", name=\"Ground truth\")\n",
    "fig = plot_poses(fgo_poses[:N], fig=fig, no_axes=True, color=\"green\", name=\"FGO\")\n",
    "fig.update_layout(height=900, width=1600, scene_aspectmode=\"data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTSAM vision factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtsam\n",
    "from gtsam.symbol_shorthand import X\n",
    "\n",
    "from gtsam import Pose3\n",
    "\n",
    "from lac.localization.gtsam_factor_graph import GtsamFactorGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = FeatureTracker(cam_config)\n",
    "\n",
    "START_FRAME = 80\n",
    "initial_pose = poses[START_FRAME]\n",
    "tracker.initialize(poses[START_FRAME], left_imgs[START_FRAME], right_imgs[START_FRAME])\n",
    "# tracker.initialize(initial_pose, left_imgs[START_FRAME], right_imgs[START_FRAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = GtsamFactorGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4000\n",
    "UPDATE_RATE = 10\n",
    "\n",
    "idx = 0\n",
    "curr_pose = initial_pose\n",
    "graph.add_pose(idx, initial_pose)\n",
    "graph.add_vision_factors(idx, tracker.world_points, tracker.prev_pts, tracker.track_ids)\n",
    "\n",
    "\n",
    "# i is step which is 0 for initial and starts at 1 for the first run_step call\n",
    "for i in tqdm(range(2, N)):\n",
    "    step = i + START_FRAME\n",
    "\n",
    "    # Run tracker\n",
    "    if i % 2 == 0:\n",
    "        if i % 10 == 0:\n",
    "            tracker.track_keyframe(poses[step], left_imgs[step], right_imgs[step])\n",
    "        else:\n",
    "            tracker.track(left_imgs[step])\n",
    "\n",
    "    # Add new pose and vision factors to graph\n",
    "    if i % UPDATE_RATE == 0:\n",
    "        idx += 1\n",
    "        noisy_pose = poses[step].copy()\n",
    "        noisy_pose[:3, 3] += np.random.normal(0, 0.0, 3)\n",
    "        graph.add_pose(idx, noisy_pose)\n",
    "        # graph.add_pose(idx, poses[step])\n",
    "        # graph.add_pose_prior(idx, noisy_pose)\n",
    "        graph.add_vision_factors(idx, tracker.world_points, tracker.prev_pts, tracker.track_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial error = {}\".format(graph.graph.error(graph.initial_estimate)))\n",
    "print(\"final error = {}\".format(graph.graph.error(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_poses = []\n",
    "result_poses = []\n",
    "\n",
    "for i in range(idx):\n",
    "    initial_poses.append(graph.initial_estimate.atPose3(X(i)).matrix())\n",
    "    result_poses.append(result.atPose3(X(i)).matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(poses[: N + START_FRAME], no_axes=True, color=\"black\", name=\"Ground truth\")\n",
    "fig = plot_poses(initial_poses, fig=fig, no_axes=True, color=\"orange\", name=\"GTSAM initial poses\")\n",
    "fig = plot_poses(result_poses, fig=fig, no_axes=True, color=\"green\", name=\"GTSAM optimized poses\")\n",
    "fig.update_layout(height=900, width=1600, scene_aspectmode=\"data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(result.atPose3(X(0)).matrix(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(poses[START_FRAME], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTSAM VIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtsam\n",
    "from gtsam.symbol_shorthand import X, L\n",
    "\n",
    "from gtsam import Pose3, PriorFactorPose3\n",
    "\n",
    "from lac.slam.gtsam_factor_graph import GtsamVIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracker = FeatureTracker(cam_config)\n",
    "tracker = FeatureTracker(cam_config, max_keypoints=2048, max_stereo_matches=1000)\n",
    "\n",
    "START_FRAME = 80\n",
    "initial_pose = poses[START_FRAME]\n",
    "tracker.initialize(poses[START_FRAME], left_imgs[START_FRAME], right_imgs[START_FRAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vio = GtsamVIO(fix_landmarks=False)\n",
    "\n",
    "# Initialize with 2 (stationary) poses\n",
    "idx = 0\n",
    "vio.add_pose(idx, initial_pose)\n",
    "vio.add_vision_factors(idx, tracker.world_points, tracker.prev_pts, tracker.track_ids)\n",
    "idx += 1\n",
    "vio.add_pose(idx, initial_pose)\n",
    "vio.add_vision_factors(idx, tracker.world_points, tracker.prev_pts, tracker.track_ids)\n",
    "latest_pose = initial_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4000\n",
    "IMG_RATE = 2\n",
    "KEYFRAME_RATE = 10\n",
    "\n",
    "for i in tqdm(range(4, N, IMG_RATE)):\n",
    "    step = i + START_FRAME\n",
    "    next_pose = latest_pose @ imu_recovery_deltas[step - 2] @ imu_recovery_deltas[step - 1]\n",
    "\n",
    "    # Run tracker\n",
    "    tracker.track_keyframe(next_pose, left_imgs[step], right_imgs[step])\n",
    "    # if i % KEYFRAME_RATE == 0:\n",
    "    #     tracker.track_keyframe(next_pose, left_imgs[step], right_imgs[step])\n",
    "    #     # TODO: we should probably add (or update) new keyframe after optimizing\n",
    "    # else:\n",
    "    #     tracker.track(left_imgs[step])\n",
    "\n",
    "    # Add new pose and vision factors to graph each frame\n",
    "    idx += 1\n",
    "    vio.add_pose(idx, next_pose)\n",
    "    vio.add_vision_factors(idx, tracker.world_points, tracker.prev_pts, tracker.track_ids)\n",
    "    result = vio.optimize(verbose=False)\n",
    "    latest_pose = result.atPose3(X(idx)).matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vio_poses = list(vio.poses.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(poses[: N + START_FRAME], no_axes=True, color=\"black\", name=\"Ground truth\")\n",
    "fig = plot_poses(vio_poses, fig=fig, no_axes=True, color=\"green\", name=\"GTSAM VIO\")\n",
    "fig.update_layout(height=900, width=1600, scene_aspectmode=\"data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"gtsam_vio.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.util import positions_rmse_from_poses, rotations_rmse_from_poses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GTSAM IMU factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtsam import imuBias, noiseModel, PriorFactorConstantBias\n",
    "from gtsam.symbol_shorthand import B, V, X, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1.622\n",
    "IMU_PARAMS = gtsam.PreintegrationParams.MakeSharedU(g)\n",
    "# I = np.eye(3)\n",
    "# IMU_PARAMS.setAccelerometerCovariance(I * 0.2)\n",
    "# IMU_PARAMS.setGyroscopeCovariance(I * 0.2)\n",
    "# IMU_PARAMS.setIntegrationCovariance(I * 0.2)\n",
    "gyro_sigma = 1e-3\n",
    "accel_sigma = 1e-3\n",
    "I_3x3 = np.eye(3)\n",
    "IMU_PARAMS.setGyroscopeCovariance(gyro_sigma**2 * I_3x3)\n",
    "IMU_PARAMS.setAccelerometerCovariance(accel_sigma**2 * I_3x3)\n",
    "IMU_PARAMS.setIntegrationCovariance(1e-7**2 * I_3x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = gtsam.NonlinearFactorGraph()\n",
    "initial_estimate = gtsam.Values()\n",
    "\n",
    "pose_noise = gtsam.noiseModel.Diagonal.Sigmas(0.2 * np.ones(6))\n",
    "# graph.push_back(gtsam.PriorFactorPose3((X(0), gtsam.Pose3(poses[0])), pose_noise))\n",
    "# Fix first pose\n",
    "graph.add(gtsam.NonlinearEqualityPose3(X(0), gtsam.Pose3(poses[0])))\n",
    "initial_estimate.insert(X(0), gtsam.Pose3(poses[0]))\n",
    "\n",
    "# IMU prior\n",
    "BIAS_KEY = B(0)\n",
    "zero_bias = imuBias.ConstantBias(np.zeros(3), np.zeros(3))\n",
    "graph.add(PriorFactorConstantBias(BIAS_KEY, zero_bias, noiseModel.Constrained.All(6)))\n",
    "initial_estimate.insert(BIAS_KEY, zero_bias)\n",
    "\n",
    "velocity_key = V(0)\n",
    "velocity_noise = gtsam.noiseModel.Isotropic.Sigma(3, 0.2)\n",
    "velocity_0 = np.array([0.0, 0.0, 0])\n",
    "graph.push_back(gtsam.PriorFactorVector(velocity_key, velocity_0, velocity_noise))\n",
    "initial_estimate.insert(velocity_key, velocity_0)\n",
    "\n",
    "# Preintegrator\n",
    "accum = gtsam.PreintegratedImuMeasurements(IMU_PARAMS)\n",
    "\n",
    "n_frames = 1000\n",
    "\n",
    "for i in range(1, n_frames):\n",
    "    accum.integrateMeasurement(imu_data[i, :3], imu_data[i, 3:], DT)\n",
    "\n",
    "    # Initialize with noisy ground truth poses\n",
    "    # initial_estimate.insert(pose_key, gtsam.Pose3(poses[i]).compose(DELTA))\n",
    "    initial_estimate.insert(X(i), gtsam.Pose3(poses[i]))\n",
    "    initial_estimate.insert(V(i), np.array([0.0, 0.0, 0]))\n",
    "\n",
    "    graph.add(gtsam.ImuFactor(X(i - 1), V(i - 1), X(i), V(i), BIAS_KEY, accum))\n",
    "\n",
    "    accum.resetIntegration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = gtsam.LevenbergMarquardtParams()\n",
    "# params.setMaxIterations(100)\n",
    "# params.setlambdaUpperBound(1.e+6)\n",
    "# params.setlambdaLowerBound(0.1)\n",
    "# params.setDiagonalDamping(1000)\n",
    "# params.setVerbosity('ERROR')\n",
    "# params.setVerbosityLM('SUMMARY')\n",
    "# params.setRelativeErrorTol(1.e-9)\n",
    "# params.setAbsoluteErrorTol(1.e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = gtsam.LevenbergMarquardtOptimizer(graph, initial_estimate, params)\n",
    "result = optimizer.optimize()\n",
    "# for i in range(10):\n",
    "#     print(f\"Iteration {i + 1}, Total Error: {graph.error(optimizer.values())}\")\n",
    "#     optimizer.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_traj = np.array([result.atPose3(X(k)).translation() for k in range(n_frames)])\n",
    "\n",
    "fig = plot_poses(poses[:n_frames], no_axes=True, color=\"black\", name=\"Ground Truth\")\n",
    "fig = plot_path_3d(est_traj, fig=fig, color=\"red\", name=\"GTSAM IMU\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
