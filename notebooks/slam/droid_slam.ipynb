{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from droid_slam.droid import Droid\n",
    "import droid_backends\n",
    "\n",
    "from lac.utils.plotting import plot_path_3d, plot_3d_points, plot_poses\n",
    "from lac.util import load_data\n",
    "from lac.params import LAC_BASE_PATH\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_stream(datapath, image_size=[360, 640], intrinsics_vec=[914.0152, 914.0152, 640.0, 360.0], stereo=False):\n",
    "    \"\"\"image generator\"\"\"\n",
    "\n",
    "    # read all png images in folder\n",
    "    ht0, wd0 = [720, 1280]\n",
    "    images_left = sorted(glob.glob(os.path.join(datapath, \"FrontLeft/*.png\")))\n",
    "    images_right = sorted(glob.glob(os.path.join(datapath, \"FrontRight/*.png\")))\n",
    "\n",
    "    data = []\n",
    "    for t in range(len(images_left)):\n",
    "        images = [cv2.resize(cv2.imread(images_left[t]), (image_size[1], image_size[0]))]\n",
    "        if stereo:\n",
    "            images += [cv2.resize(cv2.imread(images_right[t]), (image_size[1], image_size[0]))]\n",
    "\n",
    "        images = torch.from_numpy(np.stack(images, 0)).permute(0, 3, 1, 2)\n",
    "        intrinsics = 0.5 * torch.as_tensor(intrinsics_vec)\n",
    "\n",
    "        data.append((t, images, intrinsics))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--datapath\", default=\"data/LAC\")\n",
    "parser.add_argument(\"--weights\", default=\"/home/lac/opt/DROID-SLAM/droid.pth\")\n",
    "parser.add_argument(\"--buffer\", type=int, default=1000)\n",
    "parser.add_argument(\"--image_size\", default=[360, 640])\n",
    "parser.add_argument(\"--stereo\", action=\"store_true\")\n",
    "parser.add_argument(\"--disable_vis\", action=\"store_true\")\n",
    "parser.add_argument(\"--plot_curve\", action=\"store_true\")\n",
    "parser.add_argument(\"--id\", type=int, default=-1)\n",
    "\n",
    "parser.add_argument(\"--beta\", type=float, default=0.3)\n",
    "parser.add_argument(\"--filter_thresh\", type=float, default=2.4)\n",
    "parser.add_argument(\"--warmup\", type=int, default=12)\n",
    "parser.add_argument(\"--keyframe_thresh\", type=float, default=3.5)\n",
    "parser.add_argument(\"--frontend_thresh\", type=float, default=15)\n",
    "parser.add_argument(\"--frontend_window\", type=int, default=20)\n",
    "parser.add_argument(\"--frontend_radius\", type=int, default=1)\n",
    "parser.add_argument(\"--frontend_nms\", type=int, default=1)\n",
    "\n",
    "parser.add_argument(\"--backend_thresh\", type=float, default=20.0)\n",
    "parser.add_argument(\"--backend_radius\", type=int, default=2)\n",
    "parser.add_argument(\"--backend_nms\", type=int, default=3)\n",
    "parser.add_argument(\"--upsample\", action=\"store_true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(LAC_BASE_PATH) / \"output/DataCollectionAgent/stereo_side_lights1.0_map1_preset1\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\n",
    "    [\n",
    "        \"--datapath\",\n",
    "        str(data_path),\n",
    "        \"--disable_vis\",\n",
    "        \"--stereo\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = image_stream(args.datapath, stereo=args.stereo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BA_RATE = 1000\n",
    "START_FRAME = 0\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "droid = Droid(args)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for tstamp, image, intrinsics in tqdm(stream):\n",
    "    droid.track(tstamp, image, intrinsics=intrinsics)\n",
    "\n",
    "    # if tstamp % BA_RATE == 0:\n",
    "    #     droid.backend(7)\n",
    "\n",
    "print(\"Tracking ran {} frames in {} seconds\".format(len(stream), time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_est = droid.terminate(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droid.backend(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_trajectory = droid.traj_filler(stream)\n",
    "camera_trajectory = camera_trajectory.inv().data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "\n",
    "camera_poses = []\n",
    "\n",
    "for vec in camera_trajectory:\n",
    "    t = vec[:3]\n",
    "    t = np.array([t[2], -t[0], -t[1]])\n",
    "    q = vec[3:]\n",
    "    R = Rotation.from_quat(q).as_matrix()\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = t\n",
    "    camera_poses.append(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_transform = initial_pose @ np.linalg.inv(camera_poses[50])\n",
    "\n",
    "aligned_poses = [align_transform @ pose for pose in camera_poses[50:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(poses, no_axes=True, name=\"Ground Truth\", color=\"black\")\n",
    "fig = plot_poses(aligned_poses, fig=fig, no_axes=True, name=\"Droid\")\n",
    "fig.update_layout(width=1600, height=900, scene_aspectmode=\"data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lietorch import SE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = droid.video.poses\n",
    "disps = droid.video.disps\n",
    "\n",
    "\n",
    "points = droid_backends.iproj(SE3(poses).inv().data, disps, droid.video.intrinsics[0]).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = points.reshape(-1, 3).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = droid.video.counter.value\n",
    "tstamps = droid.video.tstamp[:t].cpu().numpy()\n",
    "images = droid.video.images[:t].cpu().numpy()\n",
    "disps = droid.video.disps_up[:t].cpu().numpy()\n",
    "poses = droid.video.poses[:t].cpu().numpy()\n",
    "intrinsics = droid.video.intrinsics[:t].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth scale factor\n",
    "depth_scale = 1 / 256\n",
    "\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "\n",
    "u, v = np.meshgrid(range(images.shape[3]), range(images.shape[2]))\n",
    "x = (u - intrinsics[0, 2]) * disps / intrinsics[0, 0] * depth_scale\n",
    "y = (v - intrinsics[1, 2]) * disps / intrinsics[1, 1] * depth_scale\n",
    "z = disps * depth_scale\n",
    "\n",
    "points = np.vstack((x.flatten(), y.flatten(), z.flatten(), np.ones_like(x.flatten()))).T\n",
    "\n",
    "colors = images[:, [2, 1, 0], :, :].transpose(0, 2, 3, 1).reshape(-1, 3) / 255\n",
    "\n",
    "point_cloud.points = o3d.utility.Vector3dVector(points[:, :3])\n",
    "point_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "\n",
    "for i in range(poses.shape[0]):\n",
    "    # homogeneous transform matrix로 변환\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3, :3] = Rotation.from_quat(poses[i, 3:]).as_matrix()\n",
    "    pose_matrix[:3, 3] = poses[i, :3]\n",
    "\n",
    "    # point_cloud 객체의 위치 및 방향 설정\n",
    "    point_cloud.transform(pose_matrix)\n",
    "\n",
    "\n",
    "o3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_points(pts[::100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect splat slam output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(LAC_BASE_PATH) / \"output/LocalizationAgent/map1_preset0_4m_spiral\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)\n",
    "\n",
    "output_path = Path(\"/home/lac/Splat-SLAM/output\")\n",
    "video = np.load(output_path / \"video_final.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slam_poses = video[\"poses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(poses, no_axes=True, name=\"Ground Truth\", color=\"black\")\n",
    "fig = plot_poses(slam_poses, fig=fig, no_axes=True, name=\"Splat-SLAM\")\n",
    "fig.update_layout(width=1600, height=900, scene_aspectmode=\"data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
