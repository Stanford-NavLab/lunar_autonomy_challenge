{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from droid_slam.droid import Droid\n",
    "import droid_backends\n",
    "\n",
    "from lac.utils.plotting import plot_path_3d, plot_3d_points, plot_poses\n",
    "from lac.util import load_data\n",
    "from lac.params import LAC_BASE_PATH\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_stream(\n",
    "    datapath,\n",
    "    image_size=[360, 640],\n",
    "    # image_size=[270, 480],\n",
    "    intrinsics_vec=[914.0152, 914.0152, 640.0, 360.0],\n",
    "    stereo=False,\n",
    "    start_frame=0,\n",
    "    stride=1,\n",
    "):\n",
    "    \"\"\"image generator\"\"\"\n",
    "\n",
    "    # read all png images in folder\n",
    "    ht0, wd0 = [720, 1280]\n",
    "    images_left = sorted(glob.glob(os.path.join(datapath, \"FrontLeft/*.png\")))\n",
    "    images_right = sorted(glob.glob(os.path.join(datapath, \"FrontRight/*.png\")))\n",
    "\n",
    "    data = []\n",
    "    # for t in range(start_frame, len(images_left), stride):\n",
    "    for t in range(start_frame, 100, stride):\n",
    "        images = [cv2.resize(cv2.imread(images_left[t]), (image_size[1], image_size[0]))]\n",
    "        if stereo:\n",
    "            images += [cv2.resize(cv2.imread(images_right[t]), (image_size[1], image_size[0]))]\n",
    "\n",
    "        images = torch.from_numpy(np.stack(images, 0)).permute(0, 3, 1, 2)\n",
    "        intrinsics = 0.5 * torch.as_tensor(intrinsics_vec)\n",
    "\n",
    "        data.append((t, images, intrinsics))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--datapath\", default=\"data/LAC\")\n",
    "parser.add_argument(\"--weights\", default=\"/home/lac/opt/DROID-SLAM/droid.pth\")\n",
    "parser.add_argument(\"--buffer\", type=int, default=2500)\n",
    "parser.add_argument(\"--disable_vis\", action=\"store_true\")\n",
    "# parser.add_argument(\"--plot_curve\", action=\"store_true\")\n",
    "# parser.add_argument(\"--image_size\", default=[270, 480])\n",
    "parser.add_argument(\"--image_size\", default=[360, 640])\n",
    "# parser.add_argument(\"--id\", type=int, default=-1)\n",
    "\n",
    "parser.add_argument(\"--beta\", type=float, default=0.3, help=\"weight for translation / rotation components of flow\")\n",
    "parser.add_argument(\n",
    "    \"--filter_thresh\",\n",
    "    type=float,\n",
    "    default=2.4,\n",
    "    help=\"how much motion before considering new keyframe\",\n",
    ")\n",
    "parser.add_argument(\"--warmup\", type=int, default=8, help=\"number of warmup frames\")\n",
    "parser.add_argument(\"--keyframe_thresh\", type=float, default=4.0, help=\"threshold to create a new keyframe\")\n",
    "parser.add_argument(\n",
    "    \"--frontend_thresh\",\n",
    "    type=float,\n",
    "    default=16.0,\n",
    "    help=\"add edges between frames whithin this distance\",\n",
    ")\n",
    "parser.add_argument(\"--frontend_window\", type=int, default=25, help=\"frontend optimization window\")\n",
    "parser.add_argument(\"--frontend_radius\", type=int, default=2, help=\"force edges between frames within radius\")\n",
    "parser.add_argument(\"--frontend_nms\", type=int, default=1, help=\"non-maximal supression of edges\")\n",
    "\n",
    "parser.add_argument(\"--backend_thresh\", type=float, default=20.0)\n",
    "parser.add_argument(\"--backend_radius\", type=int, default=2)\n",
    "parser.add_argument(\"--backend_nms\", type=int, default=3)\n",
    "parser.add_argument(\"--upsample\", action=\"store_true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(LAC_BASE_PATH) / \"output/DataCollectionAgent/full_spiral_map1_preset0\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])\n",
    "args.stereo = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = image_stream(str(data_path), stereo=True, start_frame=50, stride=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BA_RATE = 1000\n",
    "START_FRAME = 50\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "droid = Droid(args)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for tstamp, image, intrinsics in tqdm(stream):\n",
    "    if tstamp < START_FRAME:\n",
    "        continue\n",
    "    droid.track(tstamp, image, intrinsics=intrinsics)\n",
    "\n",
    "    # if tstamp % BA_RATE == 0:\n",
    "    #     droid.backend(7)\n",
    "\n",
    "print(\"Tracking ran {} frames in {} seconds\".format(len(stream), time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_est = droid.terminate(stream)\n",
    "np.save(\"droid_traj.npy\", traj_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect output and warping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from lac.utils.plotting import plot_path_3d, plot_3d_points, plot_poses\n",
    "from lac.utils.frames import OPENCV_TO_CAMERA_PASSIVE, opencv_to_camera\n",
    "from lac.util import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/shared/data_raw/LAC/runs/full_spiral_map1_preset0\"\n",
    "# data_path = \"/home/shared/data_raw/LAC/runs/full_spiral_map1_preset1_recovery_agent\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)\n",
    "\n",
    "# traj_est = np.load(\"/home/lac/LunarAutonomyChallenge/data/droid_trajs/droid_traj_partial.npy\")\n",
    "droid_result = np.load(Path(data_path) / \"droid.npz\")\n",
    "traj_est = droid_result[\"trajectory\"]\n",
    "\n",
    "START_FRAME = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLU_TO_OPENGL = np.array([[0, 0, -1], [1, 0, 0], [0, -1, 0]])\n",
    "\n",
    "camera_poses = []\n",
    "droid_poses = []\n",
    "ns_poses = []\n",
    "\n",
    "for vec in traj_est:\n",
    "    t = vec[:3]\n",
    "    q = vec[3:]\n",
    "    R = Rotation.from_quat(q).as_matrix()\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = t\n",
    "    droid_poses.append(T)\n",
    "\n",
    "    transf = np.eye(4)\n",
    "    transf[:3, :3] = OPENCV_TO_CAMERA_PASSIVE.T\n",
    "    T = transf @ T\n",
    "    T[:3, :3] = T[:3, :3] @ OPENCV_TO_CAMERA_PASSIVE\n",
    "    camera_poses.append(T.copy())\n",
    "    T[:3, :3] = T[:3, :3] @ FLU_TO_OPENGL\n",
    "    ns_poses.append(T.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_poses = [initial_pose @ p for p in camera_poses]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig = plot_poses(poses[100:21350], fig=fig, no_axes=True, name=\"Ground Truth\", color=\"black\")\n",
    "fig = plot_poses(aligned_poses[:-1], fig=fig, no_axes=True, name=\"Droid\")\n",
    "# fig = plot_poses(droid_poses[:1000], fig=fig, no_axes=False, name=\"Droid (aligned)\", color=\"blue\")\n",
    "# ns_poses_ds = ns_poses[::5]\n",
    "# fig = plot_poses(ns_poses_ds[:200], fig=fig, no_axes=False, name=\"Droid (aligned)\", color=\"blue\")\n",
    "fig.update_layout(width=1600, height=900, scene_aspectmode=\"data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first 10 poses (40 frames) to estimate scale\n",
    "scale = np.linalg.norm(aligned_poses[0][:3, 3] - aligned_poses[10][:3, 3]) / np.linalg.norm(\n",
    "    poses[START_FRAME][:3, 3] - poses[START_FRAME + 4 * 10][:3, 3]\n",
    ")\n",
    "print(\"Scale: \", scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lietorch import SE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = droid.video.poses\n",
    "disps = droid.video.disps\n",
    "\n",
    "\n",
    "points = droid_backends.iproj(SE3(poses).inv().data, disps, droid.video.intrinsics[0]).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = points.reshape(-1, 3).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = droid.video.counter.value\n",
    "tstamps = droid.video.tstamp[:t].cpu().numpy()\n",
    "images = droid.video.images[:t].cpu().numpy()\n",
    "disps = droid.video.disps_up[:t].cpu().numpy()\n",
    "poses = droid.video.poses[:t].cpu().numpy()\n",
    "intrinsics = droid.video.intrinsics[:t].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth scale factor\n",
    "depth_scale = 1 / 256\n",
    "\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "\n",
    "u, v = np.meshgrid(range(images.shape[3]), range(images.shape[2]))\n",
    "x = (u - intrinsics[0, 2]) * disps / intrinsics[0, 0] * depth_scale\n",
    "y = (v - intrinsics[1, 2]) * disps / intrinsics[1, 1] * depth_scale\n",
    "z = disps * depth_scale\n",
    "\n",
    "points = np.vstack((x.flatten(), y.flatten(), z.flatten(), np.ones_like(x.flatten()))).T\n",
    "\n",
    "colors = images[:, [2, 1, 0], :, :].transpose(0, 2, 3, 1).reshape(-1, 3) / 255\n",
    "\n",
    "point_cloud.points = o3d.utility.Vector3dVector(points[:, :3])\n",
    "point_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "\n",
    "for i in range(poses.shape[0]):\n",
    "    # homogeneous transform matrix로 변환\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3, :3] = Rotation.from_quat(poses[i, 3:]).as_matrix()\n",
    "    pose_matrix[:3, 3] = poses[i, :3]\n",
    "\n",
    "    # point_cloud 객체의 위치 및 방향 설정\n",
    "    point_cloud.transform(pose_matrix)\n",
    "\n",
    "\n",
    "o3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_points(pts[::100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect splat slam output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(LAC_BASE_PATH) / \"output/LocalizationAgent/map1_preset0_4m_spiral\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)\n",
    "\n",
    "output_path = Path(\"/home/lac/Splat-SLAM/output\")\n",
    "video = np.load(output_path / \"video_final.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slam_poses = video[\"poses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(poses, no_axes=True, name=\"Ground Truth\", color=\"black\")\n",
    "fig = plot_poses(slam_poses, fig=fig, no_axes=True, name=\"Splat-SLAM\")\n",
    "fig.update_layout(width=1600, height=900, scene_aspectmode=\"data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
