{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from lac.perception.segmentation import UnetSegmentation\n",
    "from lac.slam.semantic_feature_tracker import SemanticFeatureTracker\n",
    "from lac.slam.frontend import Frontend\n",
    "from lac.utils.plotting import plot_poses, plot_surface, plot_3d_points\n",
    "from lac.utils.visualization import image_grid\n",
    "from lac.util import load_data, load_stereo_images, load_images, positions_rmse_from_poses\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data logs\n",
    "# data_path = \"/home/shared/data_raw/LAC/runs/full_spiral_map1_preset0\"\n",
    "data_path = \"/home/shared/data_raw/LAC/runs/full_spiral_map1_preset1_recovery_agent\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)\n",
    "print(f\"Loaded {len(poses)} poses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = load_images(data_path, cameras=[\"FrontLeft\", \"FrontRight\"], start_frame=0, end_frame=10000)\n",
    "left_imgs, right_imgs = load_stereo_images(data_path, start_frame=0, end_frame=10000)\n",
    "images = {\"FrontLeft\": left_imgs, \"FrontRight\": right_imgs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = UnetSegmentation()\n",
    "tracker = SemanticFeatureTracker(cam_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize modules\n",
    "START_FRAME = 250\n",
    "END_FRAME = 2000\n",
    "\n",
    "pred = segmentation.predict(left_imgs[START_FRAME])\n",
    "tracker.initialize(left_imgs[START_FRAME], right_imgs[START_FRAME], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_pose = poses[START_FRAME]\n",
    "trajectory = [curr_pose]\n",
    "eval_poses = [curr_pose]\n",
    "\n",
    "# Main loop over image frames\n",
    "for frame in tqdm(range(START_FRAME + 2, END_FRAME, 2)):\n",
    "    pred = segmentation.predict(left_imgs[frame])\n",
    "    odom = tracker.track_pnp(left_imgs[frame], right_imgs[frame], pred)\n",
    "    curr_pose = curr_pose @ odom\n",
    "    trajectory.append(curr_pose)\n",
    "    eval_poses.append(poses[frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(eval_poses, no_axes=True, color=\"black\", name=\"Ground truth\")\n",
    "fig = plot_poses(trajectory, fig=fig, no_axes=True, color=\"orange\", name=\"VO poses\")\n",
    "fig.update_layout(height=900, width=1600, scene_aspectmode=\"data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_rmse_from_poses(eval_poses, trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
