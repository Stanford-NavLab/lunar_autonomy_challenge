{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from lac.perception.segmentation import Segmentation\n",
    "from lac.perception.depth import stereo_depth_from_segmentation, project_pixel_to_rover\n",
    "from lac.control.controller import rock_avoidance_steering, ArcPlanner\n",
    "from lac.utils.visualization import overlay_mask, overlay_stereo_rock_depths\n",
    "from lac.utils.plotting import (\n",
    "    plot_points_rover_frame,\n",
    "    plot_path_rover_frame,\n",
    "    plot_rocks_rover_frame,\n",
    ")\n",
    "from lac.utils.frames import invert_transform_mat\n",
    "from lac.util import load_data, get_positions_from_poses\n",
    "import lac.params as params\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obstacle detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = Segmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = Path(\"../../output/NavAgent/map1_preset4_gtnav_steer\")\n",
    "data_path = Path(\"../../output/DataCollectionAgent/map1_preset9_rocks\")\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1154\n",
    "\n",
    "left_image = Image.open(data_path / \"FrontLeft\" / f\"{i}.png\")\n",
    "right_image = Image.open(data_path / \"FrontRight\" / f\"{i}.png\")\n",
    "\n",
    "left_seg_masks, left_seg_full_mask = segmentation.segment_rocks(left_image.convert(\"RGB\"))\n",
    "right_seg_masks, right_seg_full_mask = segmentation.segment_rocks(right_image.convert(\"RGB\"))\n",
    "\n",
    "results = stereo_depth_from_segmentation(\n",
    "    left_seg_masks, right_seg_masks, params.STEREO_BASELINE, params.FL_X\n",
    ")\n",
    "left_overlay = overlay_mask(np.array(left_image), left_seg_full_mask)\n",
    "left_overlay = overlay_stereo_rock_depths(left_overlay, results)\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "plt.imshow(left_overlay)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _, w, _ = cv.boundingRect(results[0][\"left_mask\"].astype(np.uint8))\n",
    "width_x = w * results[0][\"depth\"] / params.FL_X\n",
    "print(f\"Width: {width_x} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rock_radius(results, params):\n",
    "    \"\"\"\n",
    "    Computes radii of detected rocks based on depth and bounding box width.\n",
    "\n",
    "    Args:\n",
    "        results (list): A list of dictionaries containing rock detection masks and depth values.\n",
    "        params (object): An object containing camera parameters, specifically `FL_X` (focal length in pixels).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples [(x, y, radius), ...] representing the coordinates and estimated radius of each rock.\n",
    "    \"\"\"\n",
    "    rock_data = []\n",
    "\n",
    "    for result in results:\n",
    "        if \"left_mask\" not in result or \"depth\" not in result:\n",
    "            continue  # Skip if required keys are missing\n",
    "\n",
    "        # Convert mask to uint8 and get bounding box\n",
    "        mask_uint8 = result[\"left_mask\"].astype(np.uint8)\n",
    "        x, y, w, h = cv.boundingRect(mask_uint8)\n",
    "\n",
    "        # Compute real-world width and radius using depth and focal length\n",
    "        width_real = w * result[\"depth\"] / params.FL_X\n",
    "        radius_real = width_real / 2  # Approximate the radius\n",
    "\n",
    "        rock_data.append(radius_real)\n",
    "    return rock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_points_rover_frame = []\n",
    "rock_data = extract_rock_radius(results, params)\n",
    "\n",
    "\n",
    "for rock in results:\n",
    "    rock_points_rover_frame.append(\n",
    "        project_pixel_to_rover(rock[\"left_centroid\"], rock[\"depth\"], \"FrontLeft\", cam_config)\n",
    "    )\n",
    "\n",
    "rock_points_rover_frame = np.array(rock_points_rover_frame)\n",
    "print(rock_points_rover_frame)\n",
    "plot_points_rover_frame(rock_points_rover_frame, color=\"red\")\n",
    "plot_rocks_rover_frame(rock_points_rover_frame, rock_data, color=\"blue\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics characterization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../../output/DataCollectionAgent/map1_preset0_v0.2_w-0.5\")\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform poses from world to initial local rover frame\n",
    "poses_local = [invert_transform_mat(initial_pose) @ pose for pose in poses]\n",
    "\n",
    "positions_local = get_positions_from_poses(poses_local)\n",
    "plot_path_rover_frame(positions_local, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arc path planning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = ArcPlanner()\n",
    "\n",
    "\n",
    "arcs = planner.np_candidate_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rock_points_rover_frame)\n",
    "test_rock_points_rover_frame = np.array([[0.5, 0.5], [0.4, -0.4], [0.2, 0.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rock_data = [0.07, 0.06, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"candidate arcs shape: {planner.np_candidate_arcs.shape}\")\n",
    "waypoint = np.array([0, 2])\n",
    "current_pose = np.eye(4)\n",
    "control, best_arc, waypoint_local = planner.plan_arc(\n",
    "    waypoint, current_pose, test_rock_points_rover_frame, test_rock_data\n",
    ")\n",
    "# (v,w), waypoint_local = planner.plan_arc(waypoint, current_pose, test_rock_points_rover_frame, test_rock_data)\n",
    "# print(waypoint_local)\n",
    "fig = plot_rocks_rover_frame(\n",
    "    test_rock_points_rover_frame, test_rock_data, waypoint=waypoint_local, color=\"red\"\n",
    ")\n",
    "# fig = go.Figure()\n",
    "for arc in arcs:\n",
    "    fig = plot_path_rover_frame(arc, fig=fig)\n",
    "    fig = plot_path_rover_frame(best_arc, color=\"green\", fig=fig)\n",
    "fig.show()\n",
    "print(control)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arc image overlay visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.utils.camera import Camera\n",
    "from lac.utils.frames import get_cam_pose_rover, CAMERA_TO_OPENCV_PASSIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rover_pose_to_cam_pose(rover_pose, cam_name=\"FrontLeft\"):\n",
    "    camera_pose = get_cam_pose_rover(cam_name)\n",
    "    camera_pose[:3, :3] = CAMERA_TO_OPENCV_PASSIVE\n",
    "    return rover_pose @ camera_pose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
