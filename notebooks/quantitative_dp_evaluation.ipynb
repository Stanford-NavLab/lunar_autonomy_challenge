{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Required Packages Imported Successfully\n"
     ]
    }
   ],
   "source": [
    "# Import Required Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"All Required Packages Imported Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities for handling Depth Maps in PFM format\n",
    "def read_pfm(file_path):\n",
    "    \"\"\"\n",
    "    Read a PFM file into a numpy array.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # Read header\n",
    "        header = file.readline().decode('utf-8').strip()\n",
    "        if header not in ['PF', 'Pf']:\n",
    "            raise ValueError('Not a PFM file')\n",
    "        \n",
    "        # Read dimensions\n",
    "        dim_line = file.readline().decode('utf-8').strip()\n",
    "        width, height = map(int, dim_line.split())\n",
    "        \n",
    "        # Read scale/endianness\n",
    "        scale_line = float(file.readline().decode('utf-8').strip())\n",
    "        endian = '<' if scale_line < 0 else '>'\n",
    "        \n",
    "        # Read image data\n",
    "        data = np.fromfile(file, endian + 'f')\n",
    "        shape = (height, width) if header == 'Pf' else (height, width, 3)\n",
    "        data = np.reshape(data, shape)\n",
    "        \n",
    "        # Flip array if scale is negative\n",
    "        if scale_line < 0:\n",
    "            data = np.flipud(data)\n",
    "            \n",
    "        return data\n",
    "\n",
    "def write_pfm(file_path, image, scale=1):\n",
    "    \"\"\"\n",
    "    Write a numpy array to a PFM file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'wb') as file:\n",
    "        # Write header\n",
    "        header = 'Pf\\n' if len(image.shape) == 2 else 'PF\\n'\n",
    "        file.write(header.encode('utf-8'))\n",
    "        \n",
    "        # Write dimensions\n",
    "        file.write(f'{image.shape[1]} {image.shape[0]}\\n'.encode('utf-8'))\n",
    "        \n",
    "        # Write scale/endianness\n",
    "        endian = image.dtype.byteorder\n",
    "        if endian == '<' or (endian == '=' and sys.byteorder == 'little'):\n",
    "            scale = -scale\n",
    "        file.write(f'{scale}\\n'.encode('utf-8'))\n",
    "        \n",
    "        # Write image data\n",
    "        image.tofile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load depth maps\n",
    "def load_depth_maps(pred_path, gt_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess predicted and ground truth depth maps\n",
    "    \"\"\"\n",
    "    # Load depth maps based on file extension\n",
    "    if pred_path.endswith('.pfm'):\n",
    "        pred_depth = read_pfm(pred_path)\n",
    "    else:\n",
    "        pred_depth = cv2.imread(pred_path, cv2.IMREAD_ANYDEPTH)\n",
    "        \n",
    "    if gt_path.endswith('.pfm'):\n",
    "        gt_depth = read_pfm(gt_path)\n",
    "    else:\n",
    "        gt_depth = cv2.imread(gt_path, cv2.IMREAD_ANYDEPTH)\n",
    "    \n",
    "    # Ensure same dimensions\n",
    "    if pred_depth.shape != gt_depth.shape:\n",
    "        pred_depth = cv2.resize(pred_depth, (gt_depth.shape[1], gt_depth.shape[0]))\n",
    "    \n",
    "    return pred_depth, gt_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with basic quantitative metrics\n",
    "def calculate_metrics(pred_depth, gt_depth, valid_mask=None):\n",
    "    \"\"\"\n",
    "    Calculate common depth estimation metrics\n",
    "    \n",
    "    - RMSE\n",
    "    - MAE\n",
    "    - Relative Absolute Error\n",
    "    - Relative Square Error\n",
    "    - δ1\n",
    "    - δ2\n",
    "    - δ3\n",
    "    - Correlation Coefficient\n",
    "    \"\"\"\n",
    "    if valid_mask is None:\n",
    "        valid_mask = gt_depth > 0  # Ignore zero depth pixels\n",
    "        \n",
    "    pred_valid = pred_depth[valid_mask]\n",
    "    gt_valid = gt_depth[valid_mask]\n",
    "    \n",
    "    # Root Mean Square Error\n",
    "    rmse = np.sqrt(mean_squared_error(gt_valid, pred_valid))\n",
    "    \n",
    "    # Mean Absolute Error\n",
    "    mae = mean_absolute_error(gt_valid, pred_valid)\n",
    "    \n",
    "    # Relative Absolute Error\n",
    "    rel_abs_err = np.mean(np.abs(pred_valid - gt_valid) / gt_valid)\n",
    "    \n",
    "    # Relative Square Error\n",
    "    rel_sq_err = np.mean(((pred_valid - gt_valid) ** 2) / gt_valid)\n",
    "    \n",
    "    # δ1: Percentage of pixels where relative error is less than 1.25\n",
    "    delta1 = np.mean(np.maximum(pred_valid / gt_valid, gt_valid / pred_valid) < 1.25)\n",
    "    \n",
    "    # δ2: Less than 1.25²\n",
    "    delta2 = np.mean(np.maximum(pred_valid / gt_valid, gt_valid / pred_valid) < 1.25**2)\n",
    "    \n",
    "    # δ3: Less than 1.25³\n",
    "    delta3 = np.mean(np.maximum(pred_valid / gt_valid, gt_valid / pred_valid) < 1.25**3)\n",
    "    \n",
    "    # Correlation coefficient\n",
    "    correlation, _ = pearsonr(pred_valid, gt_valid)\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'Rel_Abs_Err': rel_abs_err,\n",
    "        'Rel_Sq_Err': rel_sq_err,\n",
    "        'Delta1': delta1,\n",
    "        'Delta2': delta2,\n",
    "        'Delta3': delta3,\n",
    "        'Correlation': correlation\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare ground truth and predicted depth maps\n",
    "def visualize_comparison(pred_depth, gt_depth, metrics, save_path=None):\n",
    "    \"\"\"\n",
    "    Create visualization comparing predicted and ground truth depth maps\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Ground truth depth map\n",
    "    plt.subplot(231)\n",
    "    plt.imshow(gt_depth, cmap='viridis')\n",
    "    plt.colorbar(label='Depth (m)')\n",
    "    plt.title('Ground Truth Depth')\n",
    "    \n",
    "    # Predicted depth map\n",
    "    plt.subplot(232)\n",
    "    plt.imshow(pred_depth, cmap='viridis')\n",
    "    plt.colorbar(label='Depth (m)')\n",
    "    plt.title('Predicted Depth')\n",
    "    \n",
    "    # Error map\n",
    "    error_map = np.abs(pred_depth - gt_depth)\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(error_map, cmap='hot')\n",
    "    plt.colorbar(label='Absolute Error (m)')\n",
    "    plt.title('Error Map')\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.subplot(234)\n",
    "    valid_mask = gt_depth > 0\n",
    "    plt.scatter(gt_depth[valid_mask], pred_depth[valid_mask], \n",
    "               alpha=0.1, s=1)\n",
    "    max_depth = max(gt_depth.max(), pred_depth.max())\n",
    "    plt.plot([0, max_depth], [0, max_depth], 'r--')\n",
    "    plt.xlabel('Ground Truth Depth (m)')\n",
    "    plt.ylabel('Predicted Depth (m)')\n",
    "    plt.title('Depth Correlation')\n",
    "    \n",
    "    # Metrics text\n",
    "    plt.subplot(235)\n",
    "    plt.axis('off')\n",
    "    metrics_text = '\\n'.join([f'{k}: {v:.4f}' for k, v in metrics.items()])\n",
    "    plt.text(0.1, 0.5, metrics_text, fontsize=10)\n",
    "    plt.title('Metrics')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_classic(pred_paths, gt_paths, output_dir=None):\n",
    "    \"\"\"\n",
    "    Evaluate multiple depth maps and aggregate results\n",
    "    \"\"\"\n",
    "    all_metrics = []\n",
    "    \n",
    "    for pred_path, gt_path in zip(pred_paths, gt_paths):\n",
    "        # Load depth maps\n",
    "        pred_depth, gt_depth = load_depth_maps(pred_path, gt_path)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(pred_depth, gt_depth)\n",
    "        all_metrics.append(metrics)\n",
    "        \n",
    "        # Visualize if output directory is provided\n",
    "        if output_dir:\n",
    "            save_path = f\"{output_dir}/comparison_{pred_path.split('/')[-1]}.png\"\n",
    "            visualize_comparison(pred_depth, gt_depth, metrics, save_path)\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {\n",
    "        metric: np.mean([m[metric] for m in all_metrics])\n",
    "        for metric in all_metrics[0].keys()\n",
    "    }\n",
    "    \n",
    "    return avg_metrics, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Raycasting Evaluation on a depth map\n",
    "def raycast_evaluation(depth_map, ray_origin, ray_direction, num_samples=100):\n",
    "    \"\"\"\n",
    "    Perform raycasting evaluation on a depth map\n",
    "    \n",
    "    Args:\n",
    "        depth_map: 2D numpy array of depth values\n",
    "        ray_origin: (x, y, z) tuple for ray origin\n",
    "        ray_direction: (dx, dy, dz) tuple for ray direction (normalized)\n",
    "        num_samples: number of samples along the ray\n",
    "    \n",
    "    Returns:\n",
    "        intersections: list of intersection points\n",
    "        distances: list of distances to intersections\n",
    "    \"\"\"\n",
    "    height, width = depth_map.shape\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    y, x = np.mgrid[0:height, 0:width]\n",
    "    \n",
    "    # Convert depth map to 3D points\n",
    "    z = depth_map\n",
    "    points = np.stack([x, y, z], axis=-1)\n",
    "    \n",
    "    # Sample points along the ray\n",
    "    t = np.linspace(0, max(width, height), num_samples)\n",
    "    ray_points = ray_origin + ray_direction[:, None] * t\n",
    "    \n",
    "    # Find intersections\n",
    "    intersections = []\n",
    "    distances = []\n",
    "    \n",
    "    for i in range(1, len(t)):\n",
    "        p1 = ray_points[:, i-1]\n",
    "        p2 = ray_points[:, i]\n",
    "        \n",
    "        # Convert to pixel coordinates\n",
    "        x1, y1, z1 = p1\n",
    "        x2, y2, z2 = p2\n",
    "        \n",
    "        # Check if ray segment intersects with depth surface\n",
    "        if (0 <= x1 < width and 0 <= y1 < height and\n",
    "            0 <= x2 < width and 0 <= y2 < height):\n",
    "            \n",
    "            # Get depth at these points\n",
    "            d1 = depth_map[int(y1), int(x1)]\n",
    "            d2 = depth_map[int(y2), int(x2)]\n",
    "            \n",
    "            # Check for intersection\n",
    "            if (z1 - d1) * (z2 - d2) <= 0:\n",
    "                # Linear interpolation to find intersection\n",
    "                t_intersect = (d1 - z1) / (z2 - z1 - (d2 - d1))\n",
    "                intersection = p1 + t_intersect * (p2 - p1)\n",
    "                \n",
    "                intersections.append(intersection)\n",
    "                distances.append(np.linalg.norm(intersection - ray_origin))\n",
    "    \n",
    "    return np.array(intersections), np.array(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predicted and ground truth depth maps using raycasting\n",
    "def compare_raycasting(pred_depth, gt_depth, num_rays=100):\n",
    "    \"\"\"\n",
    "    Compare predicted and ground truth depth maps using raycasting\n",
    "    \"\"\"\n",
    "    height, width = pred_depth.shape\n",
    "    \n",
    "    # Generate random rays\n",
    "    ray_origins = np.random.rand(num_rays, 3) * np.array([width, height, 0])\n",
    "    ray_directions = np.random.rand(num_rays, 3)\n",
    "    ray_directions = ray_directions / np.linalg.norm(ray_directions, axis=1)[:, None]\n",
    "    \n",
    "    pred_errors = []\n",
    "    gt_errors = []\n",
    "    \n",
    "    for i in range(num_rays):\n",
    "        # Raycast both depth maps\n",
    "        pred_intersections, pred_distances = raycast_evaluation(\n",
    "            pred_depth, ray_origins[i], ray_directions[i])\n",
    "        gt_intersections, gt_distances = raycast_evaluation(\n",
    "            gt_depth, ray_origins[i], ray_directions[i])\n",
    "        \n",
    "        # Compare nearest intersections\n",
    "        if len(pred_distances) > 0 and len(gt_distances) > 0:\n",
    "            pred_nearest = np.min(pred_distances)\n",
    "            gt_nearest = np.min(gt_distances)\n",
    "            pred_errors.append(pred_nearest)\n",
    "            gt_errors.append(gt_nearest)\n",
    "    \n",
    "    return np.array(pred_errors), np.array(gt_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analog of evaluate_model_classic but for the raycasting depth map evaluation\n",
    "def evaluate_model_raycasting(pred_paths, gt_paths, output_dir=None, use_raycast=True):\n",
    "    \"\"\"\n",
    "    Evaluate multiple depth maps and aggregate results\n",
    "    \"\"\"\n",
    "    all_metrics = []\n",
    "    raycast_errors = []\n",
    "    \n",
    "    for pred_path, gt_path in zip(pred_paths, gt_paths):\n",
    "        # Load depth maps\n",
    "        pred_depth, gt_depth = load_depth_maps(pred_path, gt_path)\n",
    "        \n",
    "        # Calculate standard metrics\n",
    "        metrics = calculate_metrics(pred_depth, gt_depth)\n",
    "        all_metrics.append(metrics)\n",
    "        \n",
    "        # Perform raycasting evaluation if requested\n",
    "        if use_raycast:\n",
    "            pred_rays, gt_rays = compare_raycasting(pred_depth, gt_depth)\n",
    "            ray_error = np.mean(np.abs(pred_rays - gt_rays))\n",
    "            raycast_errors.append(ray_error)\n",
    "            metrics['Raycast_Error'] = ray_error\n",
    "        \n",
    "        # Visualize if output directory is provided\n",
    "        if output_dir:\n",
    "            save_path = os.path.join(output_dir, \n",
    "                                   f\"comparison_{os.path.basename(pred_path)}.png\")\n",
    "            visualize_comparison(pred_depth, gt_depth, metrics, save_path)\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {\n",
    "        metric: np.mean([m[metric] for m in all_metrics])\n",
    "        for metric in all_metrics[0].keys()\n",
    "    }\n",
    "    \n",
    "    if use_raycast:\n",
    "        avg_metrics['Avg_Raycast_Error'] = np.mean(raycast_errors)\n",
    "    \n",
    "    return avg_metrics, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace the predicted and ground truth depth maps with local paths on the Workstation\n",
    "pred_paths = ['pred_depth_1.pfm', 'pred_depth_2.pfm']\n",
    "gt_paths = ['gt_depth_1.pfm', 'gt_depth_2.pfm']\n",
    "output_dir = '/evaluation_results'\n",
    "\n",
    "# Run evaluation on classic metrics\n",
    "avg_metrics, all_metrics = evaluate_model_classic(\n",
    "    pred_paths, gt_paths, output_dir, use_raycast=True)\n",
    "\n",
    "# Run evaluation on raycasting\n",
    "avg_metrics_raycast, all_metrics_raycast = evaluate_model_raycasting(\n",
    "    pred_paths, gt_paths, output_dir, use_raycast=True)\n",
    "\n",
    "\n",
    "print(\"\\nAverage Metrics (Classic):\")\n",
    "for metric, value in avg_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "print(\"\\nAverage Metrics (Raycasting):\")\n",
    "for metric, value in avg_metrics_raycast.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stanford-LAC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
