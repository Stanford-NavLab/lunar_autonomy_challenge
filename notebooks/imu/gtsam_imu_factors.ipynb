{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gtsam\n",
    "from gtsam import imuBias, noiseModel, PriorFactorConstantBias\n",
    "from gtsam.symbol_shorthand import B, V, X, L\n",
    "\n",
    "from lac.perception.depth import project_pixel_to_rover\n",
    "from lac.utils.frames import apply_transform\n",
    "from lac.utils.plotting import plot_3d_points, plot_surface, plot_poses, plot_path_3d\n",
    "from lac.util import load_data\n",
    "from lac.params import LAC_BASE_PATH, DT\n",
    "\n",
    "from lac.slam.feature_tracker import FeatureTracker\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(LAC_BASE_PATH) / \"output/DataCollectionAgent/stereo_lights1.0_map1_preset0\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)\n",
    "print(f\"Num poses: {len(poses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMU preintegration\n",
    "\n",
    "References:\n",
    "\n",
    "- https://github.com/borglab/gtsam/blob/develop/python/gtsam/examples/ImuFactorExample.py\n",
    "- https://github.com/borglab/gtsam/blob/develop/python/gtsam/examples/PreintegrationExample.py\n",
    "- https://github.com/alextsolovikos/superpoint-gtsam-vio/blob/VIO/src/VisualInertialOdometry.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1.622\n",
    "IMU_PARAMS = gtsam.PreintegrationParams.MakeSharedU(-g)\n",
    "gyro_sigma = 1e-3\n",
    "accel_sigma = 1e-3\n",
    "# gyro_sigma = 0.5\n",
    "# accel_sigma = 0.5\n",
    "integration_sigma = 1e-7\n",
    "# integration_sigma = 0.5\n",
    "I_3x3 = np.eye(3)\n",
    "IMU_PARAMS.setGyroscopeCovariance(gyro_sigma**2 * I_3x3)\n",
    "IMU_PARAMS.setAccelerometerCovariance(accel_sigma**2 * I_3x3)\n",
    "IMU_PARAMS.setIntegrationCovariance(integration_sigma**2 * I_3x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = gtsam.NonlinearFactorGraph()\n",
    "initial_estimate = gtsam.Values()\n",
    "\n",
    "# Fix first pose\n",
    "graph.add(gtsam.NonlinearEqualityPose3(X(0), gtsam.Pose3(poses[0])))\n",
    "initial_estimate.insert(X(0), gtsam.Pose3(poses[0]))\n",
    "\n",
    "# Zero bias\n",
    "BIAS_KEY = B(0)\n",
    "zero_bias = imuBias.ConstantBias(np.zeros(3), np.zeros(3))\n",
    "# graph.add(PriorFactorConstantBias(BIAS_KEY, zero_bias, noiseModel.Constrained.All(6)))\n",
    "BIAS_NOISE = gtsam.noiseModel.Isotropic.Sigma(6, 1e-2)\n",
    "# BIAS_NOISE = gtsam.noiseModel.Isotropic.Sigma(6, 0.1)\n",
    "graph.add(PriorFactorConstantBias(BIAS_KEY, zero_bias, BIAS_NOISE))\n",
    "initial_estimate.insert(BIAS_KEY, zero_bias)\n",
    "\n",
    "# Zero initial velocity prior\n",
    "VELOCITY_NOISE = gtsam.noiseModel.Isotropic.Sigma(3, 1e-2)\n",
    "# VELOCITY_NOISE = gtsam.noiseModel.Isotropic.Sigma(3, 0.1)\n",
    "graph.push_back(gtsam.PriorFactorVector(V(0), np.zeros(3), VELOCITY_NOISE))\n",
    "initial_estimate.insert(V(0), np.zeros(3))\n",
    "\n",
    "# Preintegrator\n",
    "accum = gtsam.PreintegratedImuMeasurements(IMU_PARAMS)\n",
    "\n",
    "N_FRAMES = 1000\n",
    "RATE = 10\n",
    "\n",
    "i = 0\n",
    "\n",
    "POSE_NOISE = gtsam.noiseModel.Isotropic.Sigma(6, 1e-2)  # Stronger prior\n",
    "\n",
    "for k in range(1, N_FRAMES):\n",
    "    accel = imu_data[k, :3]\n",
    "    gyro = imu_data[k, 3:]\n",
    "    accum.integrateMeasurement(accel, gyro, DT)\n",
    "\n",
    "    if k % RATE == 0:\n",
    "        i += 1\n",
    "\n",
    "        # init pose estimate\n",
    "        initial_estimate.insert(X(i), gtsam.Pose3(poses[k]))\n",
    "\n",
    "        initial_estimate.insert(V(i), np.array([0.0, 0.0, 0]))\n",
    "        # initial_velocity = (poses[i][:3,3] - poses[i-1][:3,3]) / DT\n",
    "        # initial_estimate.insert(V(i), initial_velocity)\n",
    "\n",
    "        # add pose prior\n",
    "        graph.add(gtsam.PriorFactorPose3(X(i), gtsam.Pose3(poses[k]), POSE_NOISE))\n",
    "\n",
    "        graph.add(gtsam.ImuFactor(X(i - 1), V(i - 1), X(i), V(i), BIAS_KEY, accum))\n",
    "\n",
    "        accum.resetIntegration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = gtsam.LevenbergMarquardtParams()\n",
    "\n",
    "optimizer = gtsam.LevenbergMarquardtOptimizer(graph, initial_estimate, params)\n",
    "result = optimizer.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bias\n",
    "bias = result.atConstantBias(BIAS_KEY)\n",
    "print(f\"Bias: {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_traj = np.array([result.atPose3(X(k)).translation() for k in range(i)])\n",
    "\n",
    "fig = plot_poses(poses[:N_FRAMES], no_axes=True, color=\"black\", name=\"Ground Truth\")\n",
    "fig = plot_path_3d(est_traj, fig=fig, color=\"red\", name=\"GTSAM IMU\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stereo VO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.slam.visual_odometry import StereoVisualOdometry\n",
    "from lac.util import load_stereo_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "left_imgs, right_imgs = load_stereo_images(data_path)\n",
    "assert len(left_imgs.keys()) == len(right_imgs.keys())\n",
    "img_idxs = sorted(left_imgs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo = StereoVisualOdometry(cam_config)\n",
    "START_FRAME = 80\n",
    "svo.initialize(initial_pose, left_imgs[START_FRAME], right_imgs[START_FRAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the VO\n",
    "svo_poses = [initial_pose]\n",
    "pose_deltas = []\n",
    "\n",
    "END_FRAME = 4500\n",
    "\n",
    "for idx in tqdm(np.arange(START_FRAME + 2, END_FRAME, 2)):\n",
    "    svo.track(left_imgs[idx], right_imgs[idx])\n",
    "    svo_poses.append(svo.rover_pose)\n",
    "    pose_deltas.append(svo.pose_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = gtsam.NonlinearFactorGraph()\n",
    "values = gtsam.Values()\n",
    "\n",
    "svo_pose_sigma = 1e-2 * np.ones(6)\n",
    "svo_pose_noise = gtsam.noiseModel.Diagonal.Sigmas(svo_pose_sigma)\n",
    "\n",
    "values.insert(X(0), gtsam.Pose3(initial_pose))\n",
    "graph.add(gtsam.NonlinearEqualityPose3(X(0), gtsam.Pose3(initial_pose)))\n",
    "\n",
    "# Add odometry factors from VO\n",
    "for i in range(1, len(svo_poses)):\n",
    "    values.insert(X(i), gtsam.Pose3(svo_poses[i]))\n",
    "    graph.push_back(\n",
    "        gtsam.BetweenFactorPose3(X(i - 1), X(i), gtsam.Pose3(pose_deltas[i - 1]), svo_pose_noise)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = gtsam.LevenbergMarquardtParams()\n",
    "optimizer = gtsam.LevenbergMarquardtOptimizer(graph, values, params)\n",
    "result = optimizer.optimize()\n",
    "\n",
    "opt_poses = [result.atPose3(X(i)).matrix() for i in range(len(svo_poses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_poses(poses[:END_FRAME], no_axes=True, color=\"black\", name=\"Ground Truth\")\n",
    "fig = plot_poses(svo_poses, no_axes=True, fig=fig, color=\"red\", name=\"VO\")\n",
    "fig = plot_poses(opt_poses, no_axes=True, fig=fig, color=\"green\", name=\"Optimized\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "messing with visual-inertial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_CREATE()\n",
    "\n",
    "\n",
    "def detect_keypoints(img):\n",
    "    frame = cv2.imread(str(data_path / \"FrontLeft\" / f\"{img}.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "    keypts = orb.detect(frame, None)\n",
    "    keypts, desc = orb.compute(frame, keypts)\n",
    "    pts = np.array([kp.pt for kp in keypts], dtype=np.float32)\n",
    "    return pts, desc\n",
    "\n",
    "\n",
    "def track_mono(img, prev_img, prev_pts):\n",
    "    # track with optical flow\n",
    "    prev_frame = cv2.imread(str(data_path / \"FrontLeft\" / f\"{prev_img}.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "    next_frame = cv2.imread(str(data_path / \"FrontLeft\" / f\"{img}.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "    next_keypts, status, err = cv2.calcOpticalFlowPyrLK(prev_frame, next_frame, prev_pts, None)\n",
    "\n",
    "    # keep only valid points\n",
    "    tracked_pts = next_keypts[status.flatten() == 1]\n",
    "    return tracked_pts\n",
    "\n",
    "\n",
    "def match_features_stereo(left_pts, left_desc, right_pts, right_desc):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(left_desc, right_desc)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    good_matches = []\n",
    "    for m in matches:\n",
    "        if m.distance < 30:\n",
    "            good_matches.append(m)\n",
    "    left_pts = np.array([left_pts[m.queryIdx] for m in good_matches])\n",
    "    right_pts = np.array([right_pts[m.trainIdx] for m in good_matches])\n",
    "    return left_pts, right_pts\n",
    "\n",
    "\n",
    "def triangulate_pts_stereo(left_pts, right_pts, K, baseline):\n",
    "    # left_pts_h = np.hstack((left_pts, np.ones((left_pts.shape[0], 1))))\n",
    "    # right_pts_h = np.hstack((right_pts, np.ones((right_pts.shape[0], 1))))\n",
    "\n",
    "    disparity = left_pts[:, 0] - right_pts[:, 0]\n",
    "    disparity[disparity == 0] = 1e-6\n",
    "\n",
    "    Z = K[0, 0] * baseline / disparity\n",
    "    X = (left_pts[:, 0] - K[0, 2]) * Z / K[0, 0]\n",
    "    Y = (left_pts[:, 1] - K[1, 2]) * Z / K[1, 1]\n",
    "    pts3d = np.vstack((X, Y, Z)).T\n",
    "\n",
    "    return pts3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = gtsam.NonlinearFactorGraph()\n",
    "initial_estimate = gtsam.Values()\n",
    "\n",
    "# camera noise model\n",
    "POSE_NOISE = gtsam.noiseModel.Isotropic.Sigma(6, 1e-3)\n",
    "LANDMARK_NOISE = gtsam.noiseModel.Isotropic.Sigma(3, 1e-2)\n",
    "\n",
    "# add first pose\n",
    "graph.add(gtsam.NonlinearEqualityPose3(X(0), gtsam.Pose3(poses[0])))\n",
    "initial_estimate.insert(X(0), gtsam.Pose3(poses[0]))\n",
    "\n",
    "# add initial landmarks\n",
    "init_keypts, init_desc = detect_keypoints(img_idxs[0])\n",
    "tracked_pts = track_mono(img_idxs[1], img_idxs[0], init_keypts)\n",
    "init_landmarks = triangulate_pts(init_keypts, tracked_pts, cam_config.K, np.eye(3), np.zeros(3))\n",
    "\n",
    "for i, pt in enumerate(init_landmarks):\n",
    "    graph.add(gtsam.PriorFactorPoint3(L(i), pt.squeeze(), LANDMARK_NOISE))\n",
    "    initial_estimate.insert(L(i), pt.squeeze())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
