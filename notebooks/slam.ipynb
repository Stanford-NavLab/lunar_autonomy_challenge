{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual SLAM\n",
    "\n",
    "1. Initialization: At first frame, initialize map with 3D points from stereo.\n",
    "2. Tracking:\n",
    "   - at frame i+1, match keypoints between i and i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lac.perception.vision import LightGlueMatcher\n",
    "from lac.perception.depth import project_pixel_to_rover\n",
    "from lac.utils.frames import apply_transform\n",
    "from lac.utils.plotting import plot_3d_points, plot_surface, plot_poses\n",
    "from lac.util import load_data\n",
    "import lac.params as params\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\n",
    "    os.path.expanduser(\"~/LunarAutonomyChallenge/output/NavAgent/map1_preset4_gtnav_steer\")\n",
    ")\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)\n",
    "print(f\"Num poses: {len(poses)}\")\n",
    "\n",
    "map = np.load(\"../../data/heightmaps/competition/Moon_Map_01_preset_0.dat\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "\n",
    "left_imgs = {}\n",
    "right_imgs = {}\n",
    "\n",
    "for img_name in os.listdir(data_path / \"FrontLeft\"):\n",
    "    left_imgs[int(img_name.split(\".\")[0])] = cv2.imread(\n",
    "        str(data_path / \"FrontLeft\" / img_name), cv2.IMREAD_GRAYSCALE\n",
    "    )\n",
    "\n",
    "for img_name in os.listdir(data_path / \"FrontRight\"):\n",
    "    right_imgs[int(img_name.split(\".\")[0])] = cv2.imread(\n",
    "        str(data_path / \"FrontRight\" / img_name), cv2.IMREAD_GRAYSCALE\n",
    "    )\n",
    "\n",
    "assert len(left_imgs.keys()) == len(right_imgs.keys())\n",
    "img_idxs = sorted(left_imgs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_surface(map)\n",
    "fig = plot_poses(poses[::20], fig=fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightglue import LightGlue, SuperPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = LightGlueMatcher()\n",
    "\n",
    "feats0, feats1, matches01 = matcher.match(left_imgs[2], right_imgs[2])\n",
    "matches = matches01[\"matches\"]  # indices with shape (K,2)\n",
    "points0 = feats0[\"keypoints\"][matches[..., 0]]  # coordinates in image #0, shape (K,2)\n",
    "points1 = feats1[\"keypoints\"][matches[..., 1]]  # coordinates in image #1, shape (K,2)\n",
    "\n",
    "disparities = (points0 - points1)[:, 0]\n",
    "depths = params.FL_X * params.STEREO_BASELINE / disparities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_to_rover_points(left_img, right_img):\n",
    "    feats0, feats1, matches01 = matcher.match(left_img, right_img)\n",
    "    matches = matches01[\"matches\"]  # indices with shape (K,2)\n",
    "    points0 = feats0[\"keypoints\"][matches[..., 0]]  # coordinates in image #0, shape (K,2)\n",
    "    points1 = feats1[\"keypoints\"][matches[..., 1]]  # coordinates in image #1, shape (K,2)\n",
    "\n",
    "    disparities = (points0 - points1)[:, 0]\n",
    "    depths = params.FL_X * params.STEREO_BASELINE / disparities\n",
    "\n",
    "    points_rover = []\n",
    "    for pixel, depth in zip(points0, depths):\n",
    "        point_rover = project_pixel_to_rover(pixel, depth, \"FrontLeft\", cam_config)\n",
    "        points_rover.append(point_rover)\n",
    "    return np.array(points_rover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points_world = []\n",
    "\n",
    "for i in np.arange(100, 2000, 100):\n",
    "    points_rover = stereo_to_rover_points(left_imgs[i], right_imgs[i])\n",
    "    points_world = apply_transform(poses[i], points_rover)\n",
    "    all_points_world.append(points_world)\n",
    "\n",
    "all_points_world = np.concatenate(all_points_world, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_surface(map)\n",
    "# fig = plot_poses(poses[::20], fig=fig)\n",
    "fig = plot_3d_points(all_points_world, fig=fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MapPoint:\n",
    "    xyz: np.ndarray\n",
    "    descriptor: np.ndarray\n",
    "    label: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLAM:\n",
    "    def __init__(self):\n",
    "        self.matcher = LightGlueMatcher()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
