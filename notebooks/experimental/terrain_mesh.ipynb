{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit terrain mesh from rover images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from pytorch3d.vis.plotly_vis import plot_scene\n",
    "\n",
    "from pytorch3d_utils import structured_grid_to_pytorch3d_mesh\n",
    "from lac.utils.plotting import plot_poses\n",
    "from lac.util import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = np.load(\"../../../data/heightmaps/qualifying/Moon_Map_01_preset_0.dat\", allow_pickle=True)\n",
    "\n",
    "mesh = structured_grid_to_pytorch3d_mesh(map[..., :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the plotly figure\n",
    "fig = plot_scene({\"subplot1\": {\"map_mesh\": mesh}})\n",
    "fig.update_layout(width=1200, height=700, scene=dict(aspectmode=\"cube\"))\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(showgrid=True, showbackground=True),\n",
    "        yaxis=dict(showgrid=True, showbackground=True),\n",
    "        zaxis=dict(showgrid=True, showbackground=True),\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../../output/LocalizationAgent/map1_preset0_4m_spiral\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_poses(poses[::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the plotly figure\n",
    "fig = plot_scene({\"subplot1\": {\"map_mesh\": mesh}})\n",
    "# fig.update_layout(width=1200, height=700, scene=dict(aspectmode=\"cube\"))\n",
    "fig = plot_poses(poses[::100], fig=fig)\n",
    "fig.update_layout(width=1200, height=700, scene=dict(aspectmode=\"data\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 6500\n",
    "\n",
    "FL_gray = cv2.imread(os.path.join(data_path, \"FrontLeft\", f\"{step}.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(FL_gray, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.utils.frames import get_cam_pose_rover\n",
    "from lac.utils.frames import CAMERA_TO_OPENCV_PASSIVE\n",
    "\n",
    "rover_pose = poses[6500]\n",
    "camera_pose = get_cam_pose_rover(\"FrontLeft\")\n",
    "camera_pose[:3, :3] = CAMERA_TO_OPENCV_PASSIVE\n",
    "camera_pose = rover_pose @ camera_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch3d.renderer import (\n",
    "    PointLights,\n",
    "    FoVPerspectiveCameras,\n",
    "    RasterizationSettings,\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place a point light in front of the object. As mentioned above, the front of\n",
    "# the cow is facing the -z direction.\n",
    "lights = PointLights(device=device, location=[[0.0, 0.0, -3.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_views = 1000\n",
    "R = []\n",
    "T = []\n",
    "target_rgb = []\n",
    "\n",
    "idxs = np.arange(10, 1000, 10)\n",
    "\n",
    "for i in idxs:\n",
    "    R.append(torch.tensor(poses[i][:3, :3], device=device).float())\n",
    "    T.append(torch.tensor(poses[i][:3, 3], device=device).float())\n",
    "    img_np = cv2.imread(os.path.join(data_path, \"FrontLeft\", f\"{i}.png\"))\n",
    "    new_size = (img_np.shape[1] // 2, img_np.shape[0] // 2)\n",
    "    downscaled_img_np = cv2.resize(img_np, new_size, interpolation=cv2.INTER_AREA)\n",
    "    target_rgb.append(torch.tensor(downscaled_img_np, device=device).float())\n",
    "\n",
    "R = torch.stack(R)\n",
    "T = torch.stack(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_rgb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = FoVPerspectiveCameras(device=device, R=R, T=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_settings = RasterizationSettings(\n",
    "    image_size=(360, 640),\n",
    "    blur_radius=0.0,\n",
    "    faces_per_pixel=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
