{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "from lac.utils.plotting import plot_path_3d, plot_3d_points, plot_poses\n",
    "from lac.utils.frames import invert_transform_mat\n",
    "from lac.util import (\n",
    "    rmse,\n",
    "    get_positions_from_poses,\n",
    "    positions_rmse_from_poses,\n",
    "    rotations_rmse_from_poses,\n",
    "    load_data,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import symforce\n",
    "\n",
    "try:\n",
    "    symforce.set_epsilon_to_symbol()\n",
    "except symforce.AlreadyUsedEpsilon:\n",
    "    print(\"Already set symforce epsilon\")\n",
    "    pass\n",
    "import symforce.symbolic as sf\n",
    "\n",
    "from lac.localization.symforce_util import odometry_lander_relpose_fgo\n",
    "from lac.localization.imu_recovery import (\n",
    "    recover_rotation,\n",
    "    recover_rotation_exact,\n",
    "    recover_translation,\n",
    ")\n",
    "from lac.localization.fgo import FactorGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symforce testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "p = sf.Pose3()\n",
    "sf.Pose3(R=p.R, t=p.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_camera_cal = sf.LinearCameraCal.symbolic(\"cal\")\n",
    "display(linear_camera_cal)\n",
    "point3d = sf.V3.symbolic(\"p\")\n",
    "linear_camera_cal.pixel_from_camera_point(point3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotmat = sf.M34.ones(3, 4)\n",
    "rotmat * rotmat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sf.V3())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"../../output/imu_20hz/\" + \"data_log.json\"\n",
    "# data_path = \"../../output/Old/LocalizationAgent_spiral_norocks\"\n",
    "data_path = \"../../output/LocalizationAgent/map1_preset0_4m_spiral\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract IMU Odometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.localization.imu_recovery import ImuEstimator\n",
    "\n",
    "imu_estimator = ImuEstimator(initial_pose)\n",
    "imu_recovery_poses = [initial_pose]\n",
    "imu_recovery_deltas = []\n",
    "gt_pose_deltas = []\n",
    "\n",
    "for i in tqdm(range(len(imu_data))):\n",
    "    imu_estimator.update(imu_data[i], exact=False)\n",
    "    imu_recovery_poses.append(imu_estimator.get_pose())\n",
    "    imu_recovery_deltas.append(imu_estimator.get_pose_delta())\n",
    "    gt_pose_deltas.append(poses[i + 1] @ invert_transform_mat(poses[i]))\n",
    "\n",
    "# TODO: replace this with more principled delta estimation (integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = -1\n",
    "fig = go.Figure()\n",
    "fig = plot_poses(poses[:N], fig=fig, no_axes=True, color=\"black\", name=\"Ground truth\")\n",
    "fig = plot_poses(imu_recovery_poses[:N], fig=fig, no_axes=True, color=\"blue\", name=\"IMU recovery\")\n",
    "fig.update_layout(height=700, width=1200, scene_aspectmode=\"data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get fiducial measurements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lac.perception.vision import FiducialLocalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_localizer = FiducialLocalizer(cam_config)\n",
    "cameras = [\"FrontLeft\", \"Right\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = \"Right\"\n",
    "\n",
    "fiducial_pose_measurements = {}\n",
    "\n",
    "for cam in cameras:\n",
    "    cam_images_path = os.path.join(data_path, cam)\n",
    "    for img_path in tqdm(os.listdir(cam_images_path)):\n",
    "        i = int(img_path.split(\".\")[0])\n",
    "        img_gray = cv.imread(os.path.join(cam_images_path, img_path), cv.IMREAD_GRAYSCALE)\n",
    "        pose_measurements, _ = fid_localizer.estimate_rover_pose(img_gray, cam, lander_pose)\n",
    "        if pose_measurements:\n",
    "            if i in fiducial_pose_measurements:\n",
    "                fiducial_pose_measurements[i].extend(list(pose_measurements.values()))\n",
    "            else:\n",
    "                fiducial_pose_measurements[i] = list(pose_measurements.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_fiducial_pose_measurements = []\n",
    "\n",
    "for measurements in fiducial_pose_measurements.values():\n",
    "    unordered_fiducial_pose_measurements.extend(measurements)\n",
    "\n",
    "unordered_fiducial_position_measurements = get_positions_from_poses(\n",
    "    unordered_fiducial_pose_measurements\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ODOM_R_SIGMA = 0.0001  # for rotations\n",
    "ODOM_T_SIGMA = 0.0001  # for translations [m]\n",
    "ODOM_SIGMA = np.ones(6)\n",
    "ODOM_SIGMA[:3] *= ODOM_R_SIGMA\n",
    "ODOM_SIGMA[3:] *= ODOM_T_SIGMA\n",
    "\n",
    "FIDUCIAL_SIGMA = 0.1 * np.ones(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_graph = FactorGraph(ODOM_SIGMA, FIDUCIAL_SIGMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sliding window optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = len(poses)\n",
    "N = 4000\n",
    "UPDATE_RATE = 10\n",
    "WINDOW_SIZE = 20\n",
    "\n",
    "curr_pose = initial_pose\n",
    "factor_graph.add_pose(0, initial_pose)\n",
    "\n",
    "# i is step which is 0 for initial and starts at 1 for the first run_step call\n",
    "for i in tqdm(range(1, N)):\n",
    "    curr_pose = curr_pose @ imu_recovery_deltas[i - 1]\n",
    "    # factor_graph.add_pose(i, curr_pose)\n",
    "    # factor_graph.add_pose(i, curr_pose)\n",
    "    factor_graph.add_pose(i, poses[i])\n",
    "    # factor_graph.add_odometry_factor(i, imu_recovery_deltas[i - 1])\n",
    "    if i > 1:\n",
    "        factor_graph.add_accel_factor(i, imu_data[i - 1][:3])\n",
    "    factor_graph.add_gyro_factor(i, imu_data[i - 1][3:])\n",
    "    # if i in fiducial_pose_measurements:\n",
    "    #     # for meas in fiducial_pose_measurements[i]:\n",
    "    #     #     factor_graph.add_pose_measurement_factor(i, meas)\n",
    "    #     factor_graph.add_pose_measurement_factor(i, fiducial_pose_measurements[i][0])\n",
    "    # pass\n",
    "\n",
    "    if i % UPDATE_RATE == 0:\n",
    "        result = factor_graph.optimize(window=(i - UPDATE_RATE, i))\n",
    "        curr_pose = factor_graph.get_pose(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the whole graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = factor_graph.optimize(window=(0, len(poses) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgo_poses = factor_graph.get_all_poses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig = plot_poses(poses[:N], fig=fig, no_axes=True, color=\"black\", name=\"Ground truth\")\n",
    "fig = plot_poses(imu_recovery_poses[:N], fig=fig, no_axes=True, color=\"blue\", name=\"IMU recovery\")\n",
    "fig = plot_poses(fgo_poses[:N], fig=fig, no_axes=True, color=\"green\", name=\"FGO\")\n",
    "# fig = plot_3d_points(\n",
    "#     unordered_fiducial_position_measurements[:N],\n",
    "#     fig=fig,\n",
    "#     color=\"orange\",\n",
    "#     name=\"Fiducial measurements\",\n",
    "# )\n",
    "fig.update_layout(height=900, width=1600, scene_aspectmode=\"data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"symforce_imu_only_fgo_gt_init.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "from lac.params import FL_X, FL_Y, IMG_HEIGHT, IMG_WIDTH, LAC_BASE_PATH\n",
    "from lac.localization.symforce_util import make_pose\n",
    "from lac.localization.symforce_residuals import reprojection_residual\n",
    "from lac.localization.slam.stereo_vio import StereoVIO\n",
    "from lac.utils.frames import (\n",
    "    get_cam_pose_rover,\n",
    "    invert_transform_mat,\n",
    "    apply_transform,\n",
    "    camera_to_opencv,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(LAC_BASE_PATH) / \"output/NavAgent/map1_preset4_gtnav_steer\"\n",
    "initial_pose, lander_pose, poses, imu_data, cam_config = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: takes around 15 seconds to run\n",
    "\n",
    "left_imgs = {}\n",
    "right_imgs = {}\n",
    "\n",
    "for img_name in os.listdir(data_path / \"FrontLeft\"):\n",
    "    left_imgs[int(img_name.split(\".\")[0])] = cv2.imread(\n",
    "        str(data_path / \"FrontLeft\" / img_name), cv2.IMREAD_GRAYSCALE\n",
    "    )\n",
    "\n",
    "for img_name in os.listdir(data_path / \"FrontRight\"):\n",
    "    right_imgs[int(img_name.split(\".\")[0])] = cv2.imread(\n",
    "        str(data_path / \"FrontRight\" / img_name), cv2.IMREAD_GRAYSCALE\n",
    "    )\n",
    "\n",
    "assert len(left_imgs.keys()) == len(right_imgs.keys())\n",
    "img_idxs = sorted(left_imgs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_cal = sf.LinearCameraCal(\n",
    "    focal_length=(FL_X, FL_Y),\n",
    "    principal_point=(IMG_WIDTH / 2, IMG_HEIGHT / 2),\n",
    ")\n",
    "\n",
    "camera = sf.Camera(\n",
    "    calibration=sf.LinearCameraCal(\n",
    "        focal_length=(FL_X, FL_Y),\n",
    "        principal_point=(IMG_WIDTH / 2, IMG_HEIGHT / 2),\n",
    "    ),\n",
    "    image_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svio = StereoVIO(cam_config)\n",
    "rover_to_cam = get_cam_pose_rover(\"FrontLeft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 80\n",
    "\n",
    "world_points, kps_left = svio.triangulate_points(poses[frame], left_imgs[frame], right_imgs[frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_point = sf.V3(world_points[0])\n",
    "world_T_rover = make_pose(poses[frame])\n",
    "rover_T_cam = make_pose(rover_to_cam)\n",
    "\n",
    "reprojection_residual(\n",
    "    world_point,\n",
    "    world_T_rover,\n",
    "    rover_T_cam,\n",
    "    sf.V2(kps_left[0].astype(float)),\n",
    "    camera_cal,\n",
    "    sigma=0.1,\n",
    "    epsilon=1e-10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symforce.values import Values\n",
    "from symforce.opt.factor import Factor\n",
    "from symforce.opt.optimizer import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = Values()\n",
    "values[\"pose\"] = make_pose(poses[frame + 50])\n",
    "values[\"rover_T_cam\"] = make_pose(rover_to_cam)\n",
    "values[\"reproj_sigma\"] = 0.1\n",
    "values[\"epsilon\"] = sf.numeric_epsilon\n",
    "values[\"camera_cal\"] = sf.LinearCameraCal(\n",
    "    focal_length=(FL_X, FL_Y),\n",
    "    principal_point=(IMG_WIDTH / 2, IMG_HEIGHT / 2),\n",
    ")\n",
    "\n",
    "factors = []\n",
    "\n",
    "for i, world_point in enumerate(world_points):\n",
    "    values[f\"world_point_{i}\"] = sf.V3(world_point)\n",
    "    values[f\"kp_{i}\"] = sf.V2(kps_left[i].astype(float))\n",
    "\n",
    "    factors.append(\n",
    "        Factor(\n",
    "            residual=reprojection_residual,\n",
    "            keys=[\n",
    "                f\"world_point_{i}\",\n",
    "                \"pose\",\n",
    "                \"rover_T_cam\",\n",
    "                f\"kp_{i}\",\n",
    "                \"camera_cal\",\n",
    "                \"reproj_sigma\",\n",
    "                \"epsilon\",\n",
    "            ],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer(\n",
    "    factors=factors,\n",
    "    optimized_keys=[\"pose\"],\n",
    "    params=Optimizer.Params(\n",
    "        verbose=True, initial_lambda=1e4, iterations=100, lambda_down_factor=0.5\n",
    "    ),\n",
    ")\n",
    "result = optimizer.optimize(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.optimized_values[\"pose\"].t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses[frame][:3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses[frame + 50][:3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_rover = apply_transform(invert_transform_mat(poses[frame]), world_points[0])\n",
    "point_camera = apply_transform(invert_transform_mat(rover_to_cam), point_rover)\n",
    "point_opencv = camera_to_opencv(point_camera)\n",
    "point_opencv, point_camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.pixel_from_camera_point(point_opencv, epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_cal.pixel_from_camera_point(sf.V3(10000, 0, 0), epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel, is_valid = camera.pixel_from_camera_point(point_opencv, epsilon=1e-10)\n",
    "is_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated lander measurements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lander_position = lander_pose[:3, 3]\n",
    "\n",
    "# Lander range and bearing measurements\n",
    "lander_pose_measurements = []  # relative pose of lander in rover frame\n",
    "lander_range_measurements = []\n",
    "lander_los_measurements = []\n",
    "\n",
    "for i in range(len(poses)):\n",
    "    t_i = poses[i][:3, 3]\n",
    "    delta_t = t_i - lander_position\n",
    "    # TODO: add noise\n",
    "    lander_range_measurements.append(np.linalg.norm(delta_t))\n",
    "    lander_pose_measurements.append(invert_transform_mat(poses[i]) @ lander_pose)\n",
    "    lander_los_measurements.append(-delta_t / np.linalg.norm(delta_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WINDOW = 40\n",
    "N_SHIFT = 10\n",
    "N = 10000\n",
    "\n",
    "\n",
    "def sliding_window_fgo():\n",
    "    init_poses = imu_recovery_poses[:N_WINDOW]\n",
    "    fgo_poses = [None] * N\n",
    "    k_max = (N - N_WINDOW) // N_SHIFT\n",
    "\n",
    "    for k in (pbar := tqdm(range(k_max))):\n",
    "        window = slice(N_SHIFT * k, N_SHIFT * k + N_WINDOW)\n",
    "        odometry = imu_recovery_deltas[window][:-1]\n",
    "        # odometry = gt_odometry[window][:-1]\n",
    "        lander_measurements = lander_pose_measurements[window]\n",
    "\n",
    "        opt_poses, result = odometry_lander_relpose_fgo(\n",
    "            init_poses,\n",
    "            lander_pose,\n",
    "            odometry,\n",
    "            lander_measurements,\n",
    "            ODOM_SIGMA,\n",
    "            LANDER_RELPOSE_SIGMA,\n",
    "            debug=False,\n",
    "        )\n",
    "        fgo_poses[N_SHIFT * k : N_SHIFT * (k + 1)] = opt_poses[:N_SHIFT]\n",
    "\n",
    "        init_poses[:-N_SHIFT] = opt_poses[N_SHIFT:]\n",
    "        if k != k_max - 1:\n",
    "            pose = opt_poses[-1]\n",
    "            for i in range(N_SHIFT):\n",
    "                init_poses[-N_SHIFT + i] = pose @ imu_recovery_deltas[window][-1]\n",
    "                pose = init_poses[-N_SHIFT + i]\n",
    "\n",
    "    return fgo_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgo_poses = sliding_window_fgo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all poses not None in fgo_poses\n",
    "fgo_poses = [pose for pose in fgo_poses if pose is not None]\n",
    "N = len(fgo_poses)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig = plot_poses(poses[:N], fig=fig, no_axes=True, color=\"black\", name=\"Ground truth\")\n",
    "fig = plot_poses(imu_recovery_poses[:N], fig=fig, no_axes=True, color=\"blue\", name=\"IMU recovery\")\n",
    "fig = plot_poses(fgo_poses[:N], fig=fig, no_axes=True, color=\"green\", name=\"FGO\")\n",
    "fig.update_layout(height=700, width=1200, scene_aspectmode=\"data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
